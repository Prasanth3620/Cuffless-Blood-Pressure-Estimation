{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f209614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt\n",
    "import networkx as nx\n",
    "from scipy.ndimage import zoom\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_and_validate_data(file_path):\n",
    "    \"\"\"\n",
    "    Load data from a file and validate its presence.\n",
    "    Return None if data is invalid or shapes are inconsistent.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        loaded_data = np.load(file_path)\n",
    "        \n",
    "        \n",
    "        ppg_f = loaded_data.get('ppg_f')\n",
    "        ecg_f = loaded_data.get('ecg_f')\n",
    "        seg_dbp = loaded_data.get('seg_dbp')\n",
    "        seg_sbp = loaded_data.get('seg_sbp')\n",
    "        \n",
    "        \n",
    "        if ppg_f is None or ecg_f is None or seg_dbp is None or seg_sbp is None:\n",
    "            return None\n",
    "        \n",
    "       \n",
    "        if ppg_f.size == 0 or ecg_f.size == 0 or seg_dbp.size == 0 or seg_sbp.size == 0:\n",
    "            return None\n",
    "\n",
    "        return ppg_f, ecg_f, seg_dbp, seg_sbp\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    \"\"\"\n",
    "    Apply a bandpass filter to the data.\n",
    "    \"\"\"\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return filtfilt(b, a, data)\n",
    "\n",
    "def preprocess_signal(signal, fs):\n",
    "    \"\"\"\n",
    "    Preprocess the signal by bandpass filtering and normalization.\n",
    "    \"\"\"\n",
    "    filtered_signal = bandpass_filter(signal, 0.5, 40, fs)\n",
    "    normalized_signal = (filtered_signal - np.mean(filtered_signal)) / np.std(filtered_signal)\n",
    "    return normalized_signal\n",
    "\n",
    "def plot_vg_images(vg_images):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    num_images = len(vg_images)\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.imshow(vg_images[i], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "def combine_data_from_folder(folder_path , batch_size=100):\n",
    "    \"\"\"\n",
    "    Combine and preprocess data from all valid files in the folder and generate VG images.\n",
    "    \"\"\"\n",
    "    combined_ppg = []\n",
    "    combined_ecg = []\n",
    "    combined_seg_dbp = []\n",
    "    combined_seg_sbp = []\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        if not file_path.endswith('.npz'):\n",
    "            continue\n",
    "        \n",
    "        data = load_and_validate_data(file_path)\n",
    "        \n",
    "        if data is None:\n",
    "            print(f\"Skipping invalid file: {file_path}\")\n",
    "            continue\n",
    "        \n",
    "        ppg_f, ecg_f, seg_dbp, seg_sbp = data\n",
    "        \n",
    "        if ppg_f.ndim == 3:\n",
    "            for i in range(ppg_f.shape[0]):\n",
    "                preprocessed_ppg = preprocess_signal(ppg_f[i], 1000)\n",
    "                combined_ppg.append(preprocessed_ppg)\n",
    "        else:\n",
    "            print(f\"Skipping PPG data with unexpected shape: {ppg_f.shape}\")\n",
    "        \n",
    "        if ecg_f.ndim == 3:\n",
    "            for i in range(ecg_f.shape[0]):\n",
    "                preprocessed_ecg = preprocess_signal(ecg_f[i], 1000)\n",
    "                combined_ecg.append(preprocessed_ecg)\n",
    "        else:\n",
    "            print(f\"Skipping ECG data with unexpected shape: {ecg_f.shape}\")\n",
    "        \n",
    "        if seg_dbp.ndim == 2:\n",
    "            combined_seg_dbp.append(seg_dbp)\n",
    "        else:\n",
    "            print(f\"Skipping SegDBP data with unexpected shape: {seg_dbp.shape}\")\n",
    "        \n",
    "        if seg_sbp.ndim == 2:\n",
    "            combined_seg_sbp.append(seg_sbp)\n",
    "        else:\n",
    "            print(f\"Skipping SegSBP data with unexpected shape: {seg_sbp.shape}\")\n",
    "        \n",
    "        if len(combined_ppg) >= batch_size:\n",
    "            combined_ppg = np.stack(combined_ppg, axis=0)\n",
    "            combined_ecg = np.stack(combined_ecg, axis=0)\n",
    "            combined_seg_dbp = np.concatenate(combined_seg_dbp, axis=0)\n",
    "            combined_seg_sbp = np.concatenate(combined_seg_sbp, axis=0)\n",
    "            \n",
    "            yield combined_ppg, combined_ecg, combined_seg_dbp, combined_seg_sbp\n",
    "            \n",
    "            combined_ppg = []\n",
    "            combined_ecg = []\n",
    "            combined_seg_dbp = []\n",
    "            combined_seg_sbp = []\n",
    "            \n",
    "\n",
    "    if combined_ppg:\n",
    "        combined_ppg = np.stack(combined_ppg, axis=0)\n",
    "    else:\n",
    "        combined_ppg = np.array([])\n",
    "        \n",
    "    if combined_ecg:\n",
    "        combined_ecg = np.stack(combined_ecg, axis=0)\n",
    "    else:\n",
    "        combined_ecg = np.array([])\n",
    "        \n",
    "    if combined_seg_dbp:\n",
    "        combined_seg_dbp = np.concatenate(combined_seg_dbp, axis=0)\n",
    "    else:\n",
    "        combined_seg_dbp = np.array([])\n",
    "        \n",
    "    if combined_seg_sbp:\n",
    "        combined_seg_sbp = np.concatenate(combined_seg_sbp, axis=0)\n",
    "    else:\n",
    "        combined_seg_sbp = np.array([])\n",
    "\n",
    "    yield combined_ppg, combined_ecg, combined_seg_dbp, combined_seg_sbp\n",
    "\n",
    "\n",
    "folder_path = r'C:\\Users\\nihal\\Desktop\\NIHAL_IMP_DOCS\\Internship_PPG\\processed_npz_files_VitalDB_Final'\n",
    "\n",
    "vg_image_size = 224 \n",
    "\n",
    "\n",
    "combined_data_generator = combine_data_from_folder(folder_path,224)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c104df0",
   "metadata": {},
   "source": [
    "# FOR SINGLE BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5cbc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "vg_image_dir = 'vg_images'\n",
    "\n",
    "\n",
    "def load_vg_images(batch_idx):\n",
    "    vg_images_path = os.path.join(vg_image_dir, f'vg_images_batch_{batch_idx}.npy')\n",
    "    inverted_vg_images_path = os.path.join(vg_image_dir, f'inverted_vg_images_batch_{batch_idx}.npy')\n",
    "    \n",
    "    if not os.path.exists(vg_images_path) or not os.path.exists(inverted_vg_images_path):\n",
    "        print(f\"VG image files do not exist for Batch {batch_idx}.\")\n",
    "        return None, None\n",
    "    \n",
    "    vg_images = np.load(vg_images_path)\n",
    "    inverted_vg_images = np.load(inverted_vg_images_path)\n",
    "    \n",
    "    return vg_images, inverted_vg_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e5b1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (combined_ppg_batch, combined_ecg_batch, combined_seg_dbp_batch, combined_seg_sbp_batch) in enumerate(combined_data_generator):\n",
    "    print(f\"Processing Batch {batch_idx + 1}...\")\n",
    "\n",
    "   \n",
    "    \n",
    "    vg_images, inverted_vg_images = load_vg_images(batch_idx+1)\n",
    "\n",
    "    print(\"Flattening VG images for t-SNE...\")\n",
    "    \n",
    "    flattened_vg_images = vg_images\n",
    "    \n",
    "    print(\"Combining SBP and DBP values...\")\n",
    "    \n",
    "    y = np.column_stack((combined_seg_sbp_batch.flatten(), combined_seg_dbp_batch.flatten()))  \n",
    "    \n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5535d760",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Applying PCA...\")\n",
    "    \n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(flattened_vg_images)\n",
    "\n",
    "print(\"Applying t-SNE...\")\n",
    "    \n",
    "tsne = TSNE(n_components=3, perplexity=30)\n",
    "X_tsne = tsne.fit_transform(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c13860",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plotting t-SNE results...\")\n",
    "    \n",
    "normal_bp_condition = (q[:, 0] <= 120) | (q[:, 1] <= 80)  \n",
    "high_bp_condition = ~normal_bp_condition  \n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(P_tsne[normal_bp_condition, 0], P_tsne[normal_bp_condition, 1], \n",
    "        c='blue', marker='x', label='Normal BP')\n",
    "plt.scatter(P_tsne[high_bp_condition, 0], P_tsne[high_bp_condition, 1], \n",
    "        c='red', marker='o', label='High BP')\n",
    "plt.title('t-SNE Visualization of VG Images for PPG Signals')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Batch {batch_idx + 1} processing complete.\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65560202",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Initialize Ridge Regression model\n",
    "ridge_model = Ridge(alpha=0.1)\n",
    "\n",
    "ridge_model.fit(X_pca,y)\n",
    "\n",
    "ridge_model.predict(X_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f554364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb72501",
   "metadata": {},
   "source": [
    "# FOR MULTIPLE BATCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ae3c485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Batch 1...\n",
      "Flattening VG images for t-SNE...\n",
      "Batch 1 processing complete.\n",
      "Processing Batch 2...\n",
      "Flattening VG images for t-SNE...\n",
      "Batch 2 processing complete.\n",
      "Processing Batch 3...\n",
      "Flattening VG images for t-SNE...\n",
      "Batch 3 processing complete.\n",
      "Processing Batch 4...\n",
      "Flattening VG images for t-SNE...\n",
      "Batch 4 processing complete.\n",
      "Processing Batch 5...\n",
      "Flattening VG images for t-SNE...\n",
      "Batch 5 processing complete.\n",
      "Processing Batch 6...\n",
      "VG image files do not exist for Batch 6.\n",
      "No VG images found for Batch 6. Stopping...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vg_image_dir = 'vg_images'\n",
    "\n",
    "# Function to load VG images from a given batch index\n",
    "def load_vg_images(batch_idx):\n",
    "    vg_images_path = os.path.join(vg_image_dir, f'vg_images_batch_{batch_idx}.npy')\n",
    "    inverted_vg_images_path = os.path.join(vg_image_dir, f'inverted_vg_images_batch_{batch_idx}.npy')\n",
    "    \n",
    "    if not os.path.exists(vg_images_path) or not os.path.exists(inverted_vg_images_path):\n",
    "        print(f\"VG image files do not exist for Batch {batch_idx}.\")\n",
    "        return None, None\n",
    "    \n",
    "    vg_images = np.load(vg_images_path)\n",
    "    inverted_vg_images = np.load(inverted_vg_images_path)\n",
    "    \n",
    "    return vg_images, inverted_vg_images\n",
    "\n",
    "# Initialize lists to accumulate VG images and labels\n",
    "all_vg_images = []\n",
    "all_invrt_images = []\n",
    "all_sbp_values = []\n",
    "all_dbp_values = []\n",
    "\n",
    "\n",
    "for batch_idx, (combined_ppg_batch, combined_ecg_batch, combined_seg_dbp_batch, combined_seg_sbp_batch) in enumerate(combined_data_generator):\n",
    "    print(f\"Processing Batch {batch_idx + 1}...\")\n",
    "\n",
    "    \n",
    "    vg_images, inverted_vg_images = load_vg_images(batch_idx + 1)\n",
    "    if vg_images is None:\n",
    "        print(f\"No VG images found for Batch {batch_idx + 1}. Stopping...\")\n",
    "        break\n",
    "    print(\"Flattening VG images for t-SNE...\")\n",
    "    \n",
    "    flattened_vg_images = vg_images\n",
    "    flattened_inverted_images= inverted_vg_images\n",
    "    \n",
    "    all_vg_images.append(flattened_vg_images)\n",
    "    all_invrt_images.append(flattened_inverted_images)\n",
    "    all_sbp_values.append(combined_seg_sbp_batch.flatten())\n",
    "    all_dbp_values.append(combined_seg_dbp_batch.flatten())\n",
    "\n",
    "    print(f\"Batch {batch_idx + 1} processing complete.\")\n",
    "\n",
    "    \n",
    "\n",
    "all_vg_images = np.concatenate(all_vg_images, axis=0)\n",
    "all_invrt_images = np.concatenate(all_invrt_images, axis=0)\n",
    "all_sbp_values = np.concatenate(all_sbp_values, axis=0)\n",
    "all_dbp_values = np.concatenate(all_dbp_values, axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfa91be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4093, 50176)\n"
     ]
    }
   ],
   "source": [
    "print(all_vg_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b675a784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining SBP and DBP values...\n"
     ]
    }
   ],
   "source": [
    "print(\"Combining SBP and DBP values...\")\n",
    "# Combine SBP and DBP as labels\n",
    "q = np.column_stack((all_sbp_values, all_dbp_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5da2b549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying PCA...\n",
      "Applying t-SNE...\n"
     ]
    }
   ],
   "source": [
    "print(\"Applying PCA...\")\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=100)\n",
    "P_pca = pca.fit_transform(all_vg_images)\n",
    "PI_pca = pca.fit_transform(all_invrt_images)\n",
    "\n",
    "print(\"Applying t-SNE...\")\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=3, perplexity=30)\n",
    "P_tsne = tsne.fit_transform(P_pca)\n",
    "PI_tsne = tsne.fit_transform(PI_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "912497d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.3792953e+00, -8.7788308e-01,  8.0992355e+00],\n",
       "       [ 2.4168339e+00, -1.3485951e+00, -7.7982998e+00],\n",
       "       [ 7.1165934e+00, -2.7806994e-01, -1.0010098e+00],\n",
       "       ...,\n",
       "       [-5.1258993e+00, -2.3973907e+01,  4.7974463e+00],\n",
       "       [ 2.1295749e-02, -2.2062672e+01,  6.3254538e+00],\n",
       "       [ 1.8684341e+00, -2.2611248e+01,  6.7794847e+00]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "502c085f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.13788681, -5.8880652 ,  7.62067748, ...,  0.7385554 ,\n",
       "         1.26696676,  1.22253864],\n",
       "       [-0.5764386 ,  1.88581685, -7.25458396, ..., -0.38350507,\n",
       "        -0.27085556, -1.13445302],\n",
       "       [-0.22859395, -3.94169228,  7.08548245, ..., -1.25537313,\n",
       "         0.34196876, -1.08170369],\n",
       "       ...,\n",
       "       [ 0.51069574, -0.96911281,  2.80151871, ..., -2.03117393,\n",
       "         0.30171742, -1.93890308],\n",
       "       [-0.33968036, -0.3775972 , -1.79553166, ..., -0.94866563,\n",
       "        -0.52619603, -0.93286915],\n",
       "       [ 0.13911528, -0.90006169, -1.12458728, ..., -0.62850539,\n",
       "        -0.74351818,  0.06184352]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf6a5f1",
   "metadata": {},
   "source": [
    "# PLOTTING t-SNE FOR NORMAL VG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8808d9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plotting t-SNE results...\")\n",
    "# Plot t-SNE results\n",
    "normal_bp_condition = (q[:, 0] <= 120) | (q[:, 1] <= 80)  \n",
    "high_bp_condition = ~normal_bp_condition  \n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.scatter(P_tsne[normal_bp_condition, 0], P_tsne[normal_bp_condition, 1], \n",
    "            c='blue', marker='x', label='Normal BP')\n",
    "plt.scatter(P_tsne[high_bp_condition, 0], P_tsne[high_bp_condition, 1], \n",
    "            c='red', marker='o', label='High BP')\n",
    "plt.title('t-SNE Visualization of VG Images for PPG Signals')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddbe076",
   "metadata": {},
   "source": [
    "# PLOTTING t-SNE FOR INVERTED VG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ade07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plotting t-SNE results...\")\n",
    "# Plot t-SNE results\n",
    "normal_bp_condition = (q[:, 0] <= 120) | (q[:, 1] <= 80)  \n",
    "high_bp_condition = ~normal_bp_condition  \n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.scatter(PI_tsne[normal_bp_condition, 0], PI_tsne[normal_bp_condition, 1], \n",
    "            c='blue', marker='x', label='Normal BP')\n",
    "plt.scatter(PI_tsne[high_bp_condition, 0], PI_tsne[high_bp_condition, 1], \n",
    "            c='red', marker='o', label='High BP')\n",
    "plt.title('t-SNE Visualization of VG Images for PPG Signals')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2646aa72",
   "metadata": {},
   "source": [
    "# RIDGE REGRESSION FOR NORMAL VG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "42a42546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "vg_train,vg_test,label_train,label_test=train_test_split(P_tsne,q, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "96213a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Initialize Ridge Regression model\n",
    "ridge_model = Ridge(alpha=0.1)\n",
    "\n",
    "ridge_model.fit(vg_train,label_train)\n",
    "\n",
    "PREDICTED=ridge_model.predict(vg_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "39bfe0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[111.42947482  74.20514106]\n",
      " [145.08559425  95.22235135]\n",
      " [124.89474619  74.19285634]\n",
      " ...\n",
      " [102.59097251  63.26930883]\n",
      " [111.58027454  74.97070195]\n",
      " [123.0635736   71.20892764]]\n"
     ]
    }
   ],
   "source": [
    "print(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ed3d074c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[119.392265  74.78658 ]\n",
      " [120.24118   77.70854 ]\n",
      " [117.2084    69.42831 ]\n",
      " ...\n",
      " [115.70408   66.765434]\n",
      " [119.78525   75.55546 ]\n",
      " [116.54101   67.99354 ]]\n"
     ]
    }
   ],
   "source": [
    "print(PREDICTED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c431c98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBP Metrics: R=0.09408376307172961, MAE=13.251725218433041, RMSE=18.8319122658457, ME±SD=(-0.5943515648635542, 18.822530802361673)\n",
      "DBP Metrics: R=0.2609031756589331, MAE=8.383734847143582, RMSE=12.926223805519282, ME±SD=(-0.11361014930053939, 12.925724529184013)\n"
     ]
    }
   ],
   "source": [
    "predicted_sbp = PREDICTED[:, 0]  # Assuming the first column is SBP\n",
    "predicted_dbp = PREDICTED[:, 1]  # Assuming the second column is DBP\n",
    "\n",
    "true_sbp = label_test[:, 0]  # True SBP values from q\n",
    "true_dbp = label_test[:, 1]  # True DBP values from q\n",
    "\n",
    "def calculate_metrics(predicted, true):\n",
    "    # Calculate R (correlation coefficient)\n",
    "    R = np.corrcoef(predicted, true)[0, 1]\n",
    "\n",
    "    # Calculate MAE (Mean Absolute Error)\n",
    "    MAE = np.mean(np.abs(predicted - true))\n",
    "\n",
    "    # Calculate RMSE (Root Mean Squared Error)\n",
    "    RMSE = np.sqrt(np.mean((predicted - true) ** 2))\n",
    "\n",
    "    # Calculate ME ± SD (Mean Error ± Standard Deviation)\n",
    "    ME = np.mean(predicted - true)\n",
    "    SD = np.std(predicted - true)\n",
    "\n",
    "    return R, MAE, RMSE, (ME, SD)\n",
    "\n",
    "# Calculate metrics for SBP\n",
    "sbp_metrics = calculate_metrics(predicted_sbp, true_sbp)\n",
    "print(f\"SBP Metrics: R={sbp_metrics[0]}, MAE={sbp_metrics[1]}, RMSE={sbp_metrics[2]}, ME±SD={sbp_metrics[3]}\")\n",
    "\n",
    "# Calculate metrics for DBP\n",
    "dbp_metrics = calculate_metrics(predicted_dbp, true_dbp)\n",
    "print(f\"DBP Metrics: R={dbp_metrics[0]}, MAE={dbp_metrics[1]}, RMSE={dbp_metrics[2]}, ME±SD={dbp_metrics[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5bad894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "vg_train,vg_test,label_train,label_test=train_test_split(all_vg_images,q, test_size=0.5, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "53d23e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Initialize Ridge Regression model\n",
    "ridge_model = Ridge(alpha=0.1)\n",
    "\n",
    "ridge_model.fit(vg_train,label_train)\n",
    "\n",
    "PREDICTED=ridge_model.predict(vg_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c684398b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBP Metrics: R=0.4827649473119918, MAE=14.24032378290988, RMSE=18.758568463470958, ME±SD=(-0.8004565776150941, 18.741482333745104)\n",
      "DBP Metrics: R=0.5024925985135684, MAE=9.743388554410146, RMSE=12.948562414171704, ME±SD=(-0.1901972129159548, 12.947165466382947)\n"
     ]
    }
   ],
   "source": [
    "predicted_sbp = PREDICTED[:, 0]  # Assuming the first column is SBP\n",
    "predicted_dbp = PREDICTED[:, 1]  # Assuming the second column is DBP\n",
    "\n",
    "true_sbp = label_test[:, 0]  # True SBP values from q\n",
    "true_dbp = label_test[:, 1]  # True DBP values from q\n",
    "\n",
    "def calculate_metrics(predicted, true):\n",
    "    # Calculate R (correlation coefficient)\n",
    "    R = np.corrcoef(predicted, true)[0, 1]\n",
    "\n",
    "    # Calculate MAE (Mean Absolute Error)\n",
    "    MAE = np.mean(np.abs(predicted - true))\n",
    "\n",
    "    # Calculate RMSE (Root Mean Squared Error)\n",
    "    RMSE = np.sqrt(np.mean((predicted - true) ** 2))\n",
    "\n",
    "    # Calculate ME ± SD (Mean Error ± Standard Deviation)\n",
    "    ME = np.mean(predicted - true)\n",
    "    SD = np.std(predicted - true)\n",
    "\n",
    "    return R, MAE, RMSE, (ME, SD)\n",
    "\n",
    "# Calculate metrics for SBP\n",
    "sbp_metrics = calculate_metrics(predicted_sbp, true_sbp)\n",
    "print(f\"SBP Metrics: R={sbp_metrics[0]}, MAE={sbp_metrics[1]}, RMSE={sbp_metrics[2]}, ME±SD={sbp_metrics[3]}\")\n",
    "\n",
    "# Calculate metrics for DBP\n",
    "dbp_metrics = calculate_metrics(predicted_dbp, true_dbp)\n",
    "print(f\"DBP Metrics: R={dbp_metrics[0]}, MAE={dbp_metrics[1]}, RMSE={dbp_metrics[2]}, ME±SD={dbp_metrics[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d242c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4d31eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed3d11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "# Create a multi-output regressor\n",
    "multi_output_model = MultiOutputRegressor(BayesianRidge())\n",
    "\n",
    "# Fit the model\n",
    "multi_output_model.fit(P_pca, q)\n",
    "\n",
    "# Predict\n",
    "bayes_predict = multi_output_model.predict(P_pca)\n",
    "\n",
    "# Extract predictions for SBP and DBP\n",
    "sbp_predictions = bayes_predict[:, 0]\n",
    "dbp_predictions = bayes_predict[:, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dad87f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bayes_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef87590",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sbp =bayes_predict[:, 0]  # Assuming the first column is SBP\n",
    "predicted_dbp =bayes_predict[:, 1]  # Assuming the second column is DBP\n",
    "\n",
    "true_sbp = q[:, 0]  # True SBP values from q\n",
    "true_dbp = q[:, 1]  # True DBP values from q\n",
    "\n",
    "def calculate_metrics(predicted, true):\n",
    "    # Calculate R (correlation coefficient)\n",
    "    R = np.corrcoef(predicted, true)[0, 1]\n",
    "\n",
    "    # Calculate MAE (Mean Absolute Error)\n",
    "    MAE = np.mean(np.abs(predicted - true))\n",
    "\n",
    "    # Calculate RMSE (Root Mean Squared Error)\n",
    "    RMSE = np.sqrt(np.mean((predicted - true) ** 2))\n",
    "\n",
    "    # Calculate ME ± SD (Mean Error ± Standard Deviation)\n",
    "    ME = np.mean(predicted - true)\n",
    "    SD = np.std(predicted - true)\n",
    "\n",
    "    return R, MAE, RMSE, (ME, SD)\n",
    "\n",
    "# Calculate metrics for SBP\n",
    "sbp_metrics = calculate_metrics(predicted_sbp, true_sbp)\n",
    "print(f\"SBP Metrics: R={sbp_metrics[0]}, MAE={sbp_metrics[1]}, RMSE={sbp_metrics[2]}, ME±SD={sbp_metrics[3]}\")\n",
    "\n",
    "# Calculate metrics for DBP\n",
    "dbp_metrics = calculate_metrics(predicted_dbp, true_dbp)\n",
    "print(f\"DBP Metrics: R={dbp_metrics[0]}, MAE={dbp_metrics[1]}, RMSE={dbp_metrics[2]}, ME±SD={dbp_metrics[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f62667e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04832c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_labels = []\n",
    "for sbp, dbp in zip(predicted_sbp, predicted_dbp):\n",
    "    if sbp > 125 or dbp > 85:\n",
    "        bp_labels.append(\"high BP\")\n",
    "    else:\n",
    "        bp_labels.append(\"normal BP\")\n",
    "\n",
    "# Count occurrences\n",
    "normal_bp_count = bp_labels.count(\"normal BP\")\n",
    "high_bp_count = bp_labels.count(\"high BP\")\n",
    "\n",
    "print(f\"Normal BP count: {normal_bp_count}\")\n",
    "print(f\"High BP count: {high_bp_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9fc841",
   "metadata": {},
   "source": [
    "# RIDGE REGRESSION FOR INVERTED VG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707a73b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model.fit(P_pca,q)\n",
    "\n",
    "PREDICTED_INVERTED=ridge_model.predict(PI_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2fadbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sbp = PREDICTED_INVERTED[:, 0]  # Assuming the first column is SBP\n",
    "predicted_dbp = PREDICTED_INVERTED[:, 1]  # Assuming the second column is DBP\n",
    "\n",
    "true_sbp = q[:, 0]  # True SBP values from q\n",
    "true_dbp = q[:, 1]  # True DBP values from q\n",
    "\n",
    "def calculate_metrics(predicted, true):\n",
    "    # Calculate R (correlation coefficient)\n",
    "    R = np.corrcoef(predicted, true)[0, 1]\n",
    "\n",
    "    # Calculate MAE (Mean Absolute Error)\n",
    "    MAE = np.mean(np.abs(predicted - true))\n",
    "\n",
    "    # Calculate RMSE (Root Mean Squared Error)\n",
    "    RMSE = np.sqrt(np.mean((predicted - true) ** 2))\n",
    "\n",
    "    # Calculate ME ± SD (Mean Error ± Standard Deviation)\n",
    "    ME = np.mean(predicted - true)\n",
    "    SD = np.std(predicted - true)\n",
    "\n",
    "    return R, MAE, RMSE, (ME, SD)\n",
    "\n",
    "# Calculate metrics for SBP\n",
    "sbp_metrics = calculate_metrics(predicted_sbp, true_sbp)\n",
    "print(f\"SBP Metrics: R={sbp_metrics[0]}, MAE={sbp_metrics[1]}, RMSE={sbp_metrics[2]}, ME±SD={sbp_metrics[3]}\")\n",
    "\n",
    "# Calculate metrics for DBP\n",
    "dbp_metrics = calculate_metrics(predicted_dbp, true_dbp)\n",
    "print(f\"DBP Metrics: R={dbp_metrics[0]}, MAE={dbp_metrics[1]}, RMSE={dbp_metrics[2]}, ME±SD={dbp_metrics[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffa5a85",
   "metadata": {},
   "source": [
    "# VGG 19 FOR SINGLE BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b5f238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Load VG images (normal and inverted)\n",
    "vg_image_dir = 'vg_images'\n",
    "vg_images_normal = np.load(os.path.join(vg_image_dir, 'vg_images_batch_1.npy'))  # Adjust as needed\n",
    "vg_images_inverted = np.load(os.path.join(vg_image_dir, 'inverted_vg_images_batch_1.npy'))  # Adjust as needed\n",
    "\n",
    "# Reshape VG images for 3-channel input\n",
    "vg_images_normal_reshaped = vg_images_normal.reshape(-1, 224, 224, 1)  # Add channel dimension\n",
    "vg_images_inverted_reshaped = vg_images_inverted.reshape(-1, 224, 224, 1)\n",
    "\n",
    "# Convert to 3 channels\n",
    "vg_images_normal_rgb = np.concatenate([vg_images_normal_reshaped, vg_images_normal_reshaped, vg_images_normal_reshaped], axis=-1)\n",
    "vg_images_inverted_rgb = np.concatenate([vg_images_inverted_reshaped, vg_images_inverted_reshaped, vg_images_inverted_reshaped], axis=-1)\n",
    "\n",
    "# Preprocess images\n",
    "vg_images_normal_preprocessed = preprocess_input(vg_images_normal_rgb)\n",
    "vg_images_inverted_preprocessed = preprocess_input(vg_images_inverted_rgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea70af38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VGG19 model without the top classifier layers\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Create a feature extraction model\n",
    "feature_extractor = Model(inputs=base_model.input, outputs=base_model.output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0083c63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "vg_features_normal = feature_extractor.predict(vg_images_normal_preprocessed)\n",
    "vg_features_inverted = feature_extractor.predict(vg_images_inverted_preprocessed)\n",
    "\n",
    "# Flatten the features\n",
    "vg_features_normal_flattened = vg_features_normal.reshape(vg_features_normal.shape[0], -1)\n",
    "vg_features_inverted_flattened = vg_features_inverted.reshape(vg_features_inverted.shape[0], -1)\n",
    "\n",
    "# Combine features\n",
    "vg_features_combined = np.hstack((vg_features_normal_flattened, vg_features_inverted_flattened))  # Shape: (N, P)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbf9f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Ridge Regression\n",
    "ridge_model = Ridge(alpha=1.0)  # Adjust regularization parameter as needed\n",
    "ridge_model.fit(vg_features_combined, y)\n",
    "\n",
    "# Predict SBP and DBP values\n",
    "predicted_values = ridge_model.predict(vg_features_combined)\n",
    "\n",
    "print(predicted_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbb2462",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c24771",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sbp = predicted_values[:, 0]  # Assuming the first column is SBP\n",
    "predicted_dbp = predicted_values[:, 1]  # Assuming the second column is DBP\n",
    "\n",
    "true_sbp = y[:, 0]  # True SBP values from q\n",
    "true_dbp = y[:, 1]  # True DBP values from q\n",
    "\n",
    "def calculate_metrics(predicted, true):\n",
    "    # Calculate R (correlation coefficient)\n",
    "    R = np.corrcoef(predicted, true)[0, 1]\n",
    "\n",
    "    # Calculate MAE (Mean Absolute Error)\n",
    "    MAE = np.mean(np.abs(predicted - true))\n",
    "\n",
    "    # Calculate RMSE (Root Mean Squared Error)\n",
    "    RMSE = np.sqrt(np.mean((predicted - true) ** 2))\n",
    "\n",
    "    # Calculate ME ± SD (Mean Error ± Standard Deviation)\n",
    "    ME = np.mean(predicted - true)\n",
    "    SD = np.std(predicted - true)\n",
    "\n",
    "    return R, MAE, RMSE, (ME, SD)\n",
    "\n",
    "# Calculate metrics for SBP\n",
    "sbp_metrics = calculate_metrics(predicted_sbp, true_sbp)\n",
    "print(f\"SBP Metrics: R={sbp_metrics[0]}, MAE={sbp_metrics[1]}, RMSE={sbp_metrics[2]}, ME±SD={sbp_metrics[3]}\")\n",
    "\n",
    "# Calculate metrics for DBP\n",
    "dbp_metrics = calculate_metrics(predicted_dbp, true_dbp)\n",
    "print(f\"DBP Metrics: R={dbp_metrics[0]}, MAE={dbp_metrics[1]}, RMSE={dbp_metrics[2]}, ME±SD={dbp_metrics[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e761b2",
   "metadata": {},
   "source": [
    "# VGG19 FOR MULTIPLE BATCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d21d1bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "vg_images_normal = all_vg_images\n",
    "vg_images_inverted = all_invrt_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9c96997",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "def image_generator(images, batch_size):\n",
    "    num_samples = images.shape[0]\n",
    "    for offset in range(0, num_samples, batch_size):\n",
    "        batch_images = images[offset:offset+batch_size]\n",
    "        batch_images_reshaped = batch_images.reshape(-1, 224, 224, 1)\n",
    "        batch_images_rgb = np.concatenate([batch_images_reshaped] * 3, axis=-1)\n",
    "        batch_images_preprocessed = preprocess_input(batch_images_rgb)\n",
    "        yield batch_images_preprocessed\n",
    "\n",
    "\n",
    "base_model = VGG19(weights='imagenet', include_top=True, input_shape=(224, 224, 3))\n",
    "\n",
    "\n",
    "#feature_extractor = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "feature_extractor = Model(inputs=base_model.input, outputs=base_model.get_layer('fc1').output)\n",
    "\n",
    "def extract_features(generator, num_samples):\n",
    "    features = []\n",
    "    for batch in generator:\n",
    "        batch_features = feature_extractor.predict(batch)\n",
    "        features.append(batch_features)\n",
    "    return np.vstack(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ff56fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 143,667,240\n",
      "Trainable params: 143,667,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ec6e4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,788,928\n",
      "Trainable params: 122,788,928\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9dcb406e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 4s 4s/step\n"
     ]
    }
   ],
   "source": [
    "num_samples_normal = vg_images_normal.shape[0]\n",
    "num_samples_inverted = vg_images_inverted.shape[0]\n",
    "\n",
    "\n",
    "normal_generator = image_generator(vg_images_normal, batch_size)\n",
    "inverted_generator = image_generator(vg_images_inverted, batch_size)\n",
    "\n",
    "\n",
    "vg_features_normal = extract_features(normal_generator, num_samples_normal)\n",
    "vg_features_inverted = extract_features(inverted_generator, num_samples_inverted)\n",
    "\n",
    "\n",
    "vg_features_normal_flattened = vg_features_normal.reshape(vg_features_normal.shape[0], -1)\n",
    "vg_features_inverted_flattened = vg_features_inverted.reshape(vg_features_inverted.shape[0], -1)\n",
    "\n",
    "\n",
    "vg_features_combined = np.hstack((vg_features_normal_flattened, vg_features_inverted_flattened))  # Shape: (N, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c28560d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[116.43793   76.99057 ]\n",
      " [122.60095   75.38452 ]\n",
      " [114.535736  70.599976]\n",
      " ...\n",
      " [115.66052   71.652954]\n",
      " [127.835846  76.837494]\n",
      " [116.53198   66.91861 ]]\n"
     ]
    }
   ],
   "source": [
    "ridge_model = Ridge(alpha=1.0)  \n",
    "ridge_model.fit(vg_features_combined, q)\n",
    "\n",
    "\n",
    "predicted_values = ridge_model.predict(vg_features_combined)\n",
    "\n",
    "print(predicted_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab5e9461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBP Metrics: R=0.772797072279392, MAE=9.155812839188988, RMSE=12.157537586010443, ME±SD=(0.0005058169353249202, 12.157537575488133)\n",
      "DBP Metrics: R=0.790184526373008, MAE=5.9226458632022005, RMSE=8.282380747120175, ME±SD=(-0.00013118982836539695, 8.282380746081177)\n"
     ]
    }
   ],
   "source": [
    "predicted_sbp =predicted_values[:, 0]  # Assuming the first column is SBP\n",
    "predicted_dbp =predicted_values[:, 1]  # Assuming the second column is DBP\n",
    "\n",
    "true_sbp = q[:, 0]  # True SBP values from q\n",
    "true_dbp = q[:, 1]  # True DBP values from q\n",
    "\n",
    "def calculate_metrics(predicted, true):\n",
    "    # Calculate R (correlation coefficient)\n",
    "    R = np.corrcoef(predicted, true)[0, 1]\n",
    "\n",
    "    # Calculate MAE (Mean Absolute Error)\n",
    "    MAE = np.mean(np.abs(predicted - true))\n",
    "\n",
    "    # Calculate RMSE (Root Mean Squared Error)\n",
    "    RMSE = np.sqrt(np.mean((predicted - true) ** 2))\n",
    "\n",
    "    # Calculate ME ± SD (Mean Error ± Standard Deviation)\n",
    "    ME = np.mean(predicted - true)\n",
    "    SD = np.std(predicted - true)\n",
    "\n",
    "    return R, MAE, RMSE, (ME, SD)\n",
    "\n",
    "# Calculate metrics for SBP\n",
    "sbp_metrics = calculate_metrics(predicted_sbp, true_sbp)\n",
    "print(f\"SBP Metrics: R={sbp_metrics[0]}, MAE={sbp_metrics[1]}, RMSE={sbp_metrics[2]}, ME±SD={sbp_metrics[3]}\")\n",
    "\n",
    "# Calculate metrics for DBP\n",
    "dbp_metrics = calculate_metrics(predicted_dbp, true_dbp)\n",
    "print(f\"DBP Metrics: R={dbp_metrics[0]}, MAE={dbp_metrics[1]}, RMSE={dbp_metrics[2]}, ME±SD={dbp_metrics[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc9d4be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,570,240\n",
      "Trainable params: 139,570,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature_extractor2 = Model(inputs=base_model.input, outputs=base_model.get_layer('fc2').output)\n",
    "feature_extractor2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e59bd5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features2(generator, num_samples):\n",
    "    features = []\n",
    "    for batch in generator:\n",
    "        batch_features = feature_extractor2.predict(batch)\n",
    "        features.append(batch_features)\n",
    "    return np.vstack(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "426f2151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 8s 8s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n"
     ]
    }
   ],
   "source": [
    "num_samples_normal = vg_images_normal.shape[0]\n",
    "num_samples_inverted = vg_images_inverted.shape[0]\n",
    "\n",
    "\n",
    "normal_generator = image_generator(vg_images_normal, batch_size)\n",
    "inverted_generator = image_generator(vg_images_inverted, batch_size)\n",
    "\n",
    "\n",
    "vg_features_normal2 = extract_features2(normal_generator, num_samples_normal)\n",
    "vg_features_inverted2 = extract_features2(inverted_generator, num_samples_inverted)\n",
    "\n",
    "\n",
    "vg_features_normal_flattened2 = vg_features_normal2.reshape(vg_features_normal2.shape[0], -1)\n",
    "vg_features_inverted_flattened2 = vg_features_inverted2.reshape(vg_features_inverted2.shape[0], -1)\n",
    "\n",
    "\n",
    "vg_features_combined2 = np.hstack((vg_features_normal_flattened2, vg_features_inverted_flattened2))  # Shape: (N, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42dd6c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "vg_features_train,vg_features_test,label_vgg_train,label_vgg_test=train_test_split(vg_features_combined2,q, test_size=0.2, random_state=42)\n",
    "ridge_model = Ridge(alpha=1.0)  \n",
    "ridge_model.fit(vg_features_train, label_vgg_train)\n",
    "\n",
    "\n",
    "predicted_values_split = ridge_model.predict(vg_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d2c6818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBP Metrics: R=0.7025930805917515, MAE=10.249272953918561, RMSE=13.327511856126822, ME±SD=(-0.680277537550576, 13.310138795185614)\n",
      "DBP Metrics: R=0.7228155490015689, MAE=6.570788409793689, RMSE=9.177056106088898, ME±SD=(-0.3094514739362396, 9.171837251040941)\n"
     ]
    }
   ],
   "source": [
    "predicted_sbp =predicted_values_split[:, 0]  # Assuming the first column is SBP\n",
    "predicted_dbp =predicted_values_split[:, 1]  # Assuming the second column is DBP\n",
    "\n",
    "true_sbp = label_vgg_test[:, 0]  # True SBP values from q\n",
    "true_dbp = label_vgg_test[:, 1]  # True DBP values from q\n",
    "\n",
    "def calculate_metrics(predicted, true):\n",
    "    # Calculate R (correlation coefficient)\n",
    "    R = np.corrcoef(predicted, true)[0, 1]\n",
    "\n",
    "    # Calculate MAE (Mean Absolute Error)\n",
    "    MAE = np.mean(np.abs(predicted - true))\n",
    "\n",
    "    # Calculate RMSE (Root Mean Squared Error)\n",
    "    RMSE = np.sqrt(np.mean((predicted - true) ** 2))\n",
    "\n",
    "    # Calculate ME ± SD (Mean Error ± Standard Deviation)\n",
    "    ME = np.mean(predicted - true)\n",
    "    SD = np.std(predicted - true)\n",
    "\n",
    "    return R, MAE, RMSE, (ME, SD)\n",
    "\n",
    "# Calculate metrics for SBP\n",
    "sbp_metrics = calculate_metrics(predicted_sbp, true_sbp)\n",
    "print(f\"SBP Metrics: R={sbp_metrics[0]}, MAE={sbp_metrics[1]}, RMSE={sbp_metrics[2]}, ME±SD={sbp_metrics[3]}\")\n",
    "\n",
    "# Calculate metrics for DBP\n",
    "dbp_metrics = calculate_metrics(predicted_dbp, true_dbp)\n",
    "print(f\"DBP Metrics: R={dbp_metrics[0]}, MAE={dbp_metrics[1]}, RMSE={dbp_metrics[2]}, ME±SD={dbp_metrics[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702ba883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23be01e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7214d1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Function to generate image batches\n",
    "def image_generator(images, labels, batch_size):\n",
    "    num_samples = images.shape[0]\n",
    "    while True:\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_images = images[offset:offset+batch_size]\n",
    "            batch_labels = labels[offset:offset+batch_size]\n",
    "            batch_images_reshaped = batch_images.reshape(-1, 224, 224, 1)\n",
    "            batch_images_rgb = np.concatenate([batch_images_reshaped] * 3, axis=-1)\n",
    "            batch_images_preprocessed = preprocess_input(batch_images_rgb)\n",
    "            yield batch_images_preprocessed, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cbde11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 2002      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 143,669,242\n",
      "Trainable params: 2,002\n",
      "Non-trainable params: 143,667,240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "\n",
    "# Load the VGG19 model with pre-trained ImageNet weights and without the top layer\n",
    "base_model = VGG19(weights='imagenet', include_top=True, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "x = base_model.output\n",
    "#x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "#x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "output = Dense(2, activation='linear')(x)  # Adjust the output layer according to your task\n",
    "\n",
    "# Create a new model with the modified top layer\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Print a summary to verify the layers are frozen\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a390fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the base VGG19 model with the top layers\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "output = Dense(2, activation='linear')(x)  # Adjust the output layer according to your task\n",
    "\n",
    "# Create a new model with the modified top layer\n",
    "model = Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49e0427a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 8194      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,578,434\n",
      "Trainable params: 139,578,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c37ff0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nihal\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 2638s 21s/step - loss: 984.7535 - mae: 21.3258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ab921fef50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Assuming you have images and labels loaded\n",
    "images = vg_images_normal\n",
    "labels = q\n",
    "\n",
    "# Create the image generator\n",
    "train_generator = image_generator(images, labels, batch_size)\n",
    "\n",
    "# Train the model\n",
    "num_samples = images.shape[0]\n",
    "model.fit(train_generator, steps_per_epoch=num_samples // batch_size, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4562a45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 10s 10s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 9s 9s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n"
     ]
    }
   ],
   "source": [
    "# Define a new model to extract features from the 'fc1' layer of the trained model\n",
    "feature_extractor = Model(inputs=model.input, outputs=model.get_layer('fc1').output)\n",
    "\n",
    "# Function to extract features\n",
    "def extract_features(generator, num_samples):\n",
    "    features = []\n",
    "    for batch_images, _ in generator:\n",
    "        batch_features = feature_extractor.predict(batch_images)\n",
    "        features.append(batch_features)\n",
    "        if len(features) * batch_size >= num_samples:\n",
    "            break\n",
    "    return np.vstack(features)\n",
    "\n",
    "# Create the generator for feature extraction (no labels needed)\n",
    "feature_generator_normal = image_generator(images, np.zeros((num_samples,)), batch_size)\n",
    "feature_generator_inverted = image_generator(vg_images_inverted, np.zeros((num_samples,)), batch_size)\n",
    "\n",
    "# Extract features\n",
    "features_normal = extract_features(feature_generator_normal, num_samples)\n",
    "features_inverted = extract_features(feature_generator_inverted, num_samples)\n",
    "\n",
    "features_normal_flattened= features_normal.reshape(features_normal.shape[0],-1)\n",
    "features_inverted_flattened= features_inverted.reshape(features_inverted.shape[0],-1)\n",
    "\n",
    "features= np.hstack((features_normal_flattened,features_inverted_flattened))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cb2f545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "vg_features_train,vg_features_test,label_vgg_train,label_vgg_test=train_test_split(features,q, test_size=0.2, random_state=42)\n",
    "ridge_model = Ridge(alpha=1.0)  \n",
    "ridge_model.fit(vg_features_train, label_vgg_train)\n",
    "\n",
    "\n",
    "predicted_values_split = ridge_model.predict(vg_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0300cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBP Metrics: R=0.2004484189452353, MAE=13.616361949466357, RMSE=18.24446058044627, ME±SD=(-1.399250513359489, 18.190724006270916)\n",
      "DBP Metrics: R=0.1983167134292075, MAE=9.396296807851911, RMSE=12.998157420654644, ME±SD=(-0.9204670452789594, 12.965524931551164)\n"
     ]
    }
   ],
   "source": [
    "predicted_sbp =predicted_values_split[:, 0]  # Assuming the first column is SBP\n",
    "predicted_dbp =predicted_values_split[:, 1]  # Assuming the second column is DBP\n",
    "\n",
    "true_sbp = label_vgg_test[:, 0]  # True SBP values from q\n",
    "true_dbp = label_vgg_test[:, 1]  # True DBP values from q\n",
    "\n",
    "def calculate_metrics(predicted, true):\n",
    "    # Calculate R (correlation coefficient)\n",
    "    R = np.corrcoef(predicted, true)[0, 1]\n",
    "\n",
    "    # Calculate MAE (Mean Absolute Error)\n",
    "    MAE = np.mean(np.abs(predicted - true))\n",
    "\n",
    "    # Calculate RMSE (Root Mean Squared Error)\n",
    "    RMSE = np.sqrt(np.mean((predicted - true) ** 2))\n",
    "\n",
    "    # Calculate ME ± SD (Mean Error ± Standard Deviation)\n",
    "    ME = np.mean(predicted - true)\n",
    "    SD = np.std(predicted - true)\n",
    "\n",
    "    return R, MAE, RMSE, (ME, SD)\n",
    "\n",
    "# Calculate metrics for SBP\n",
    "sbp_metrics = calculate_metrics(predicted_sbp, true_sbp)\n",
    "print(f\"SBP Metrics: R={sbp_metrics[0]}, MAE={sbp_metrics[1]}, RMSE={sbp_metrics[2]}, ME±SD={sbp_metrics[3]}\")\n",
    "\n",
    "# Calculate metrics for DBP\n",
    "dbp_metrics = calculate_metrics(predicted_dbp, true_dbp)\n",
    "print(f\"DBP Metrics: R={dbp_metrics[0]}, MAE={dbp_metrics[1]}, RMSE={dbp_metrics[2]}, ME±SD={dbp_metrics[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa57a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99283818",
   "metadata": {},
   "outputs": [],
   "source": [
    "orgininal_Mean_sbp=np.mean(q[:,0])\n",
    "orgininal_Mean_dbp=np.mean(q[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ea05c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_SD_sbp=np.std(orgininal_Mean_sbp-q[:,0])\n",
    "original_SD_dbp=np.std(orgininal_Mean_dbp-q[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19a0f605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original standard deviation of sbp: 19.092041821560084\n",
      "original standard deviation of dbp: 13.45258445160312\n"
     ]
    }
   ],
   "source": [
    "print('original standard deviation of sbp:',original_SD_sbp)\n",
    "print('original standard deviation of dbp:',original_SD_dbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13850ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003ae35e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1261e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f157b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "vg_features_train,vg_features_test,label_vgg_train,label_vgg_test=train_test_split(vg_features_combined,q, test_size=0.2, random_state=42)\n",
    "ridge_model = Ridge(alpha=1.0)  \n",
    "ridge_model.fit(vg_features_train, label_vgg_train)\n",
    "\n",
    "\n",
    "predicted_values_split = ridge_model.predict(vg_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7921c507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBP Metrics: R=0.7393615884079727, MAE=9.680599027440008, RMSE=12.56047092306476, ME±SD=(-0.5797904002439807, 12.547082246520114)\n",
      "DBP Metrics: R=0.7679653162002857, MAE=6.177144039920629, RMSE=8.488757550977363, ME±SD=(-0.27434023643242406, 8.484323319743856)\n"
     ]
    }
   ],
   "source": [
    "predicted_sbp =predicted_values_split[:, 0]  # Assuming the first column is SBP\n",
    "predicted_dbp =predicted_values_split[:, 1]  # Assuming the second column is DBP\n",
    "\n",
    "true_sbp = label_vgg_test[:, 0]  # True SBP values from q\n",
    "true_dbp = label_vgg_test[:, 1]  # True DBP values from q\n",
    "\n",
    "def calculate_metrics(predicted, true):\n",
    "    # Calculate R (correlation coefficient)\n",
    "    R = np.corrcoef(predicted, true)[0, 1]\n",
    "\n",
    "    # Calculate MAE (Mean Absolute Error)\n",
    "    MAE = np.mean(np.abs(predicted - true))\n",
    "\n",
    "    # Calculate RMSE (Root Mean Squared Error)\n",
    "    RMSE = np.sqrt(np.mean((predicted - true) ** 2))\n",
    "\n",
    "    # Calculate ME ± SD (Mean Error ± Standard Deviation)\n",
    "    ME = np.mean(predicted - true)\n",
    "    SD = np.std(predicted - true)\n",
    "\n",
    "    return R, MAE, RMSE, (ME, SD)\n",
    "\n",
    "# Calculate metrics for SBP\n",
    "sbp_metrics = calculate_metrics(predicted_sbp, true_sbp)\n",
    "print(f\"SBP Metrics: R={sbp_metrics[0]}, MAE={sbp_metrics[1]}, RMSE={sbp_metrics[2]}, ME±SD={sbp_metrics[3]}\")\n",
    "\n",
    "# Calculate metrics for DBP\n",
    "dbp_metrics = calculate_metrics(predicted_dbp, true_dbp)\n",
    "print(f\"DBP Metrics: R={dbp_metrics[0]}, MAE={dbp_metrics[1]}, RMSE={dbp_metrics[2]}, ME±SD={dbp_metrics[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d015082f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac771b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad0137b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b1ad22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original VG images shape: (4093, 50176)\n",
      "Extended VG images shape: (4093, 224, 224)\n",
      "Resized VG images shape: (4093, 3, 224, 224)\n",
      "Original VG images shape: (4093, 50176)\n",
      "Extended VG images shape: (4093, 224, 224)\n",
      "Resized VG images shape: (4093, 3, 224, 224)\n",
      "VG features shape: (4093, 512, 7, 7)\n",
      "Inverted VG features shape: (4093, 512, 7, 7)\n",
      "Combined features shape: (4093, 50176)\n",
      "[[117.3998    77.530785]\n",
      " [115.71025   70.64775 ]\n",
      " [116.23215   71.17795 ]\n",
      " ...\n",
      " [141.7895    81.69441 ]\n",
      " [146.8068    84.19699 ]\n",
      " [146.71292   85.36191 ]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torchvision.models import vgg19\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Define a batch size\n",
    "batch_size = 16  # Use a smaller batch size to manage memory\n",
    "\n",
    "# Define a function to preprocess VG images\n",
    "def preprocess_vg_images(vg_images, target_size=(224, 224)):\n",
    "    print(f\"Original VG images shape: {vg_images.shape}\")\n",
    "    vg_images_extended = vg_images.reshape(-1, 224, 224)  # Ensure images are reshaped correctly\n",
    "    print(f\"Extended VG images shape: {vg_images_extended.shape}\")\n",
    "    \n",
    "    resize_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(target_size),\n",
    "        transforms.Grayscale(num_output_channels=3),  # Convert grayscale to RGB\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    vg_images_resized = []\n",
    "    for image in vg_images_extended:\n",
    "        transformed_image = resize_transform(image)\n",
    "        vg_images_resized.append(transformed_image.numpy())\n",
    "    \n",
    "    vg_images_resized = np.array(vg_images_resized)\n",
    "    print(f\"Resized VG images shape: {vg_images_resized.shape}\")\n",
    "    return vg_images_resized\n",
    "\n",
    "# Load VG images and inverted VG images (replace this with actual loading code)\n",
    "vg_images = all_vg_images\n",
    "inverted_vg_images = all_invrt_images\n",
    "\n",
    "# Preprocess VG images and inverted VG images\n",
    "vg_images_resized = preprocess_vg_images(vg_images)\n",
    "inverted_vg_images_resized = preprocess_vg_images(inverted_vg_images)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "vg_images_tensor = torch.tensor(vg_images_resized, dtype=torch.float32)\n",
    "inverted_vg_images_tensor = torch.tensor(inverted_vg_images_resized, dtype=torch.float32)\n",
    "\n",
    "# Create TensorDatasets\n",
    "vg_dataset = TensorDataset(vg_images_tensor)\n",
    "inverted_vg_dataset = TensorDataset(inverted_vg_images_tensor)\n",
    "\n",
    "# Create DataLoaders\n",
    "vg_loader = DataLoader(vg_dataset, batch_size=batch_size, shuffle=False)\n",
    "inverted_vg_loader = DataLoader(inverted_vg_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Load VGG19 model and remove the top layers\n",
    "model = vgg19(weights='VGG19_Weights.DEFAULT')\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Define a function to extract features in batches\n",
    "def extract_features(loader):\n",
    "    features = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch_images = batch[0]\n",
    "            batch_features = model(batch_images)\n",
    "            features.append(batch_features.squeeze().numpy())\n",
    "    return np.vstack(features)\n",
    "\n",
    "# Extract features from VG images and inverted VG images in batches\n",
    "vg_features = extract_features(vg_loader)\n",
    "inverted_vg_features = extract_features(inverted_vg_loader)\n",
    "\n",
    "print(f\"VG features shape: {vg_features.shape}\")\n",
    "print(f\"Inverted VG features shape: {inverted_vg_features.shape}\")\n",
    "\n",
    "# Flatten the features\n",
    "vg_features_flattened = vg_features.reshape(vg_features.shape[0], -1)\n",
    "inverted_vg_features_flattened = inverted_vg_features.reshape(inverted_vg_features.shape[0], -1)\n",
    "\n",
    "# Combine VG features and inverted VG features\n",
    "combined_features = np.hstack((vg_features_flattened, inverted_vg_features_flattened))\n",
    "print(f\"Combined features shape: {combined_features.shape}\")\n",
    "\n",
    "# Fit a Ridge regression model\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(combined_features, q)\n",
    "\n",
    "# Predict SBP and DBP values\n",
    "predictions = ridge.predict(combined_features)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd984b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBP Metrics: R=0.9994690989845076, MAE=0.4871802901805776, RMSE=0.6426835897578517, ME±SD=(-0.00015217686876435428, 0.6426835717413657)\n",
      "DBP Metrics: R=0.9994915580394712, MAE=0.3326262971835257, RMSE=0.4432602140310017, ME±SD=(8.402787939906152e-05, 0.44326020606650995)\n"
     ]
    }
   ],
   "source": [
    "predicted_sbp =predictions[:, 0]  # Assuming the first column is SBP\n",
    "predicted_dbp =predictions[:, 1]  # Assuming the second column is DBP\n",
    "\n",
    "true_sbp = q[:, 0]  # True SBP values from q\n",
    "true_dbp = q[:, 1]  # True DBP values from q\n",
    "\n",
    "def calculate_metrics(predicted, true):\n",
    "    # Calculate R (correlation coefficient)\n",
    "    R = np.corrcoef(predicted, true)[0, 1]\n",
    "\n",
    "    # Calculate MAE (Mean Absolute Error)\n",
    "    MAE = np.mean(np.abs(predicted - true))\n",
    "\n",
    "    # Calculate RMSE (Root Mean Squared Error)\n",
    "    RMSE = np.sqrt(np.mean((predicted - true) ** 2))\n",
    "\n",
    "    # Calculate ME ± SD (Mean Error ± Standard Deviation)\n",
    "    ME = np.mean(predicted - true)\n",
    "    SD = np.std(predicted - true)\n",
    "\n",
    "    return R, MAE, RMSE, (ME, SD)\n",
    "\n",
    "# Calculate metrics for SBP\n",
    "sbp_metrics = calculate_metrics(predicted_sbp, true_sbp)\n",
    "print(f\"SBP Metrics: R={sbp_metrics[0]}, MAE={sbp_metrics[1]}, RMSE={sbp_metrics[2]}, ME±SD={sbp_metrics[3]}\")\n",
    "\n",
    "# Calculate metrics for DBP\n",
    "dbp_metrics = calculate_metrics(predicted_dbp, true_dbp)\n",
    "print(f\"DBP Metrics: R={dbp_metrics[0]}, MAE={dbp_metrics[1]}, RMSE={dbp_metrics[2]}, ME±SD={dbp_metrics[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e5924ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "vg_features2_train,vg_features2_test,label_vgg2_train,label_vgg2_test=train_test_split(combined_features,q, test_size=0.5, random_state=42)\n",
    "ridge_model = Ridge(alpha=1.0)  \n",
    "ridge_model.fit(vg_features2_train, label_vgg2_train)\n",
    "\n",
    "\n",
    "predicted_values2_split = ridge_model.predict(vg_features2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d6bea1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBP Metrics: R=0.6905491016342521, MAE=11.004855136935634, RMSE=14.448826650120834, ME±SD=(0.3414734326884799, 14.444791014757186)\n",
      "DBP Metrics: R=0.7078827862102354, MAE=7.6090561932947605, RMSE=10.072771913413334, ME±SD=(0.35926332227121105, 10.066362991911188)\n"
     ]
    }
   ],
   "source": [
    "predicted_sbp =predicted_values2_split[:, 0]  # Assuming the first column is SBP\n",
    "predicted_dbp =predicted_values2_split[:, 1]  # Assuming the second column is DBP\n",
    "\n",
    "true_sbp = label_vgg2_test[:, 0]  # True SBP values from q\n",
    "true_dbp = label_vgg2_test[:, 1]  # True DBP values from q\n",
    "\n",
    "def calculate_metrics(predicted, true):\n",
    "    # Calculate R (correlation coefficient)\n",
    "    R = np.corrcoef(predicted, true)[0, 1]\n",
    "\n",
    "    # Calculate MAE (Mean Absolute Error)\n",
    "    MAE = np.mean(np.abs(predicted - true))\n",
    "\n",
    "    # Calculate RMSE (Root Mean Squared Error)\n",
    "    RMSE = np.sqrt(np.mean((predicted - true) ** 2))\n",
    "\n",
    "    # Calculate ME ± SD (Mean Error ± Standard Deviation)\n",
    "    ME = np.mean(predicted - true)\n",
    "    SD = np.std(predicted - true)\n",
    "\n",
    "    return R, MAE, RMSE, (ME, SD)\n",
    "\n",
    "# Calculate metrics for SBP\n",
    "sbp_metrics = calculate_metrics(predicted_sbp, true_sbp)\n",
    "print(f\"SBP Metrics: R={sbp_metrics[0]}, MAE={sbp_metrics[1]}, RMSE={sbp_metrics[2]}, ME±SD={sbp_metrics[3]}\")\n",
    "\n",
    "# Calculate metrics for DBP\n",
    "dbp_metrics = calculate_metrics(predicted_dbp, true_dbp)\n",
    "print(f\"DBP Metrics: R={dbp_metrics[0]}, MAE={dbp_metrics[1]}, RMSE={dbp_metrics[2]}, ME±SD={dbp_metrics[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a0f89f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
