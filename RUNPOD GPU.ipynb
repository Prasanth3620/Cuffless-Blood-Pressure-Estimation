{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "163db877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cupy\n",
      "  Downloading cupy-13.3.0.tar.gz (3.4 MB)\n",
      "     ---------------------------------------- 0.0/3.4 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/3.4 MB ? eta -:--:--\n",
      "     --- ------------------------------------ 0.3/3.4 MB ? eta -:--:--\n",
      "     ------------ --------------------------- 1.0/3.4 MB 3.6 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 2.1/3.4 MB 4.5 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 2.6/3.4 MB 4.4 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 2.9/3.4 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.4/3.4 MB 3.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy<2.3,>=1.22 in c:\\users\\nihal\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from cupy) (1.24.3)\n",
      "Collecting fastrlock>=0.5 (from cupy)\n",
      "  Using cached fastrlock-0.8.2-cp310-cp310-win_amd64.whl.metadata (9.6 kB)\n",
      "Using cached fastrlock-0.8.2-cp310-cp310-win_amd64.whl (29 kB)\n",
      "Building wheels for collected packages: cupy\n",
      "  Building wheel for cupy (setup.py): started\n",
      "  Building wheel for cupy (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for cupy\n",
      "Failed to build cupy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [57 lines of output]\n",
      "  Generating cache key from header files...\n",
      "  Cache key (1610 files matching C:\\Users\\nihal\\AppData\\Local\\Temp\\pip-install-hxjp550h\\cupy_b450889ecb0d41d487c8e610f93e18bb\\cupy\\_core\\include\\**): 6d15f8ff018dac193d6bd2dcc599f463a0e286a8\n",
      "  Clearing directory: C:\\Users\\nihal\\AppData\\Local\\Temp\\pip-install-hxjp550h\\cupy_b450889ecb0d41d487c8e610f93e18bb\\cupy\\.data\n",
      "  Looking for NVTX: C:\\Program Files\\NVIDIA Corporation\\Nsight Systems *\\target-windows-x64\\nvtx\n",
      "  NVTX could not be found\n",
      "  \n",
      "  -------- Configuring Module: cuda --------\n",
      "  Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  **************************************************\n",
      "  *** WARNING: Cannot check compute capability\n",
      "  Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  **************************************************\n",
      "  \n",
      "  ************************************************************\n",
      "  * CuPy Configuration Summary                               *\n",
      "  ************************************************************\n",
      "  \n",
      "  Build Environment:\n",
      "    Include directories: ['C:\\\\Users\\\\nihal\\\\AppData\\\\Local\\\\Temp\\\\pip-install-hxjp550h\\\\cupy_b450889ecb0d41d487c8e610f93e18bb\\\\cupy/_core/include\\\\cupy/_cccl/libcudacxx', 'C:\\\\Users\\\\nihal\\\\AppData\\\\Local\\\\Temp\\\\pip-install-hxjp550h\\\\cupy_b450889ecb0d41d487c8e610f93e18bb\\\\cupy/_core/include\\\\cupy/_cccl/thrust', 'C:\\\\Users\\\\nihal\\\\AppData\\\\Local\\\\Temp\\\\pip-install-hxjp550h\\\\cupy_b450889ecb0d41d487c8e610f93e18bb\\\\cupy/_core/include\\\\cupy/_cccl/cub', 'C:\\\\Users\\\\nihal\\\\AppData\\\\Local\\\\Temp\\\\pip-install-hxjp550h\\\\cupy_b450889ecb0d41d487c8e610f93e18bb\\\\cupy/_core/include']\n",
      "    Library directories: []\n",
      "    nvcc command       : (not found)\n",
      "    hipcc command      : (not found)\n",
      "  \n",
      "  Environment Variables:\n",
      "    CFLAGS          : (none)\n",
      "    LDFLAGS         : (none)\n",
      "    LIBRARY_PATH    : (none)\n",
      "    CUDA_PATH       : (none)\n",
      "    NVCC            : (none)\n",
      "    HIPCC           : (none)\n",
      "    ROCM_HOME       : (none)\n",
      "  \n",
      "  Modules:\n",
      "    cuda      : No\n",
      "      -> Include files not found: ['cublas_v2.h', 'cuda.h', 'cuda_profiler_api.h', 'cuda_runtime.h', 'cufft.h', 'curand.h', 'cusparse.h']\n",
      "      -> Check your CFLAGS environment variable.\n",
      "  \n",
      "  ERROR: CUDA could not be found on your system.\n",
      "  \n",
      "  HINT: You are trying to build CuPy from source, which is NOT recommended for general use.\n",
      "        Please consider using binary packages instead.\n",
      "  \n",
      "  Please refer to the Installation Guide for details:\n",
      "  https://docs.cupy.dev/en/stable/install.html\n",
      "  \n",
      "  ************************************************************\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"C:\\Users\\nihal\\AppData\\Local\\Temp\\pip-install-hxjp550h\\cupy_b450889ecb0d41d487c8e610f93e18bb\\setup.py\", line 95, in <module>\n",
      "      ext_modules = cupy_setup_build.get_ext_modules(True, ctx)\n",
      "    File \"C:\\Users\\nihal\\AppData\\Local\\Temp\\pip-install-hxjp550h\\cupy_b450889ecb0d41d487c8e610f93e18bb\\install\\cupy_builder\\cupy_setup_build.py\", line 514, in get_ext_modules\n",
      "      extensions = make_extensions(ctx, compiler, use_cython)\n",
      "    File \"C:\\Users\\nihal\\AppData\\Local\\Temp\\pip-install-hxjp550h\\cupy_b450889ecb0d41d487c8e610f93e18bb\\install\\cupy_builder\\cupy_setup_build.py\", line 363, in make_extensions\n",
      "      raise Exception('Your CUDA environment is invalid. '\n",
      "  Exception: Your CUDA environment is invalid. Please check above error log.\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for cupy\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py clean did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [57 lines of output]\n",
      "  Generating cache key from header files...\n",
      "  Cache key (1610 files matching C:\\Users\\nihal\\AppData\\Local\\Temp\\pip-install-hxjp550h\\cupy_b450889ecb0d41d487c8e610f93e18bb\\cupy\\_core\\include\\**): 6d15f8ff018dac193d6bd2dcc599f463a0e286a8\n",
      "  Clearing directory: C:\\Users\\nihal\\AppData\\Local\\Temp\\pip-install-hxjp550h\\cupy_b450889ecb0d41d487c8e610f93e18bb\\cupy\\.data\n",
      "  Looking for NVTX: C:\\Program Files\\NVIDIA Corporation\\Nsight Systems *\\target-windows-x64\\nvtx\n",
      "  NVTX could not be found\n",
      "  \n",
      "  -------- Configuring Module: cuda --------\n",
      "  Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  **************************************************\n",
      "  *** WARNING: Cannot check compute capability\n",
      "  Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  **************************************************\n",
      "  \n",
      "  ************************************************************\n",
      "  * CuPy Configuration Summary                               *\n",
      "  ************************************************************\n",
      "  \n",
      "  Build Environment:\n",
      "    Include directories: ['C:\\\\Users\\\\nihal\\\\AppData\\\\Local\\\\Temp\\\\pip-install-hxjp550h\\\\cupy_b450889ecb0d41d487c8e610f93e18bb\\\\cupy/_core/include\\\\cupy/_cccl/libcudacxx', 'C:\\\\Users\\\\nihal\\\\AppData\\\\Local\\\\Temp\\\\pip-install-hxjp550h\\\\cupy_b450889ecb0d41d487c8e610f93e18bb\\\\cupy/_core/include\\\\cupy/_cccl/thrust', 'C:\\\\Users\\\\nihal\\\\AppData\\\\Local\\\\Temp\\\\pip-install-hxjp550h\\\\cupy_b450889ecb0d41d487c8e610f93e18bb\\\\cupy/_core/include\\\\cupy/_cccl/cub', 'C:\\\\Users\\\\nihal\\\\AppData\\\\Local\\\\Temp\\\\pip-install-hxjp550h\\\\cupy_b450889ecb0d41d487c8e610f93e18bb\\\\cupy/_core/include']\n",
      "    Library directories: []\n",
      "    nvcc command       : (not found)\n",
      "    hipcc command      : (not found)\n",
      "  \n",
      "  Environment Variables:\n",
      "    CFLAGS          : (none)\n",
      "    LDFLAGS         : (none)\n",
      "    LIBRARY_PATH    : (none)\n",
      "    CUDA_PATH       : (none)\n",
      "    NVCC            : (none)\n",
      "    HIPCC           : (none)\n",
      "    ROCM_HOME       : (none)\n",
      "  \n",
      "  Modules:\n",
      "    cuda      : No\n",
      "      -> Include files not found: ['cublas_v2.h', 'cuda.h', 'cuda_profiler_api.h', 'cuda_runtime.h', 'cufft.h', 'curand.h', 'cusparse.h']\n",
      "      -> Check your CFLAGS environment variable.\n",
      "  \n",
      "  ERROR: CUDA could not be found on your system.\n",
      "  \n",
      "  HINT: You are trying to build CuPy from source, which is NOT recommended for general use.\n",
      "        Please consider using binary packages instead.\n",
      "  \n",
      "  Please refer to the Installation Guide for details:\n",
      "  https://docs.cupy.dev/en/stable/install.html\n",
      "  \n",
      "  ************************************************************\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"C:\\Users\\nihal\\AppData\\Local\\Temp\\pip-install-hxjp550h\\cupy_b450889ecb0d41d487c8e610f93e18bb\\setup.py\", line 95, in <module>\n",
      "      ext_modules = cupy_setup_build.get_ext_modules(True, ctx)\n",
      "    File \"C:\\Users\\nihal\\AppData\\Local\\Temp\\pip-install-hxjp550h\\cupy_b450889ecb0d41d487c8e610f93e18bb\\install\\cupy_builder\\cupy_setup_build.py\", line 514, in get_ext_modules\n",
      "      extensions = make_extensions(ctx, compiler, use_cython)\n",
      "    File \"C:\\Users\\nihal\\AppData\\Local\\Temp\\pip-install-hxjp550h\\cupy_b450889ecb0d41d487c8e610f93e18bb\\install\\cupy_builder\\cupy_setup_build.py\", line 363, in make_extensions\n",
      "      raise Exception('Your CUDA environment is invalid. '\n",
      "  Exception: Your CUDA environment is invalid. Please check above error log.\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed cleaning build dir for cupy\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (cupy)\n"
     ]
    }
   ],
   "source": [
    "!pip install cupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "314e27b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numba in c:\\users\\nihal\\anaconda3\\envs\\tensorflow\\lib\\site-packages (0.57.1)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in c:\\users\\nihal\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from numba) (0.40.0)\n",
      "Requirement already satisfied: numpy<1.25,>=1.21 in c:\\users\\nihal\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from numba) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09d4baa6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cupy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msignal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m butter, filtfilt\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnx\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cupy'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "from scipy.signal import butter, filtfilt\n",
    "import networkx as nx\n",
    "from scipy.ndimage import zoom\n",
    "import matplotlib.pyplot as plt\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from numba import jit, prange\n",
    "\n",
    "# Load and Validate Data\n",
    "def load_and_validate_data(file_path):\n",
    "    try:\n",
    "        loaded_data = np.load(file_path)\n",
    "        ppg_f = loaded_data.get('ppg_f')\n",
    "        ecg_f = loaded_data.get('ecg_f')\n",
    "        seg_dbp = loaded_data.get('seg_dbp')\n",
    "        seg_sbp = loaded_data.get('seg_sbp')\n",
    "        \n",
    "        if ppg_f is None or ecg_f is None or seg_dbp is None or seg_sbp is None:\n",
    "            return None\n",
    "        \n",
    "        if ppg_f.size == 0 or ecg_f.size == 0 or seg_dbp.size == 0 or seg_sbp.size == 0:\n",
    "            return None\n",
    "\n",
    "        return ppg_f, ecg_f, seg_dbp, seg_sbp\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Bandpass Filter using GPU (CuPy)\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    \n",
    "    data_gpu = cp.asarray(data)\n",
    "    filtered_data_gpu = filtfilt(b, a, data_gpu)\n",
    "    return cp.asnumpy(filtered_data_gpu)\n",
    "\n",
    "# Preprocess Signal using GPU (CuPy)\n",
    "def preprocess_signal(signal, fs):\n",
    "    filtered_signal = bandpass_filter(signal, 0.5, 40, fs)\n",
    "    normalized_signal = (filtered_signal - cp.mean(filtered_signal)) / cp.std(filtered_signal)\n",
    "    return cp.asnumpy(normalized_signal)\n",
    "\n",
    "# Visibility Graph Creation (Numba)\n",
    "@jit(nopython=True, parallel=True)\n",
    "def create_visibility_graph(ppg_signal):\n",
    "    n = len(ppg_signal)\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(range(n))\n",
    "\n",
    "    for i in prange(n):\n",
    "        for j in range(i + 1, n):\n",
    "            visible = True\n",
    "            for k in range(i + 1, j):\n",
    "                if ppg_signal[k] >= ppg_signal[i] + (ppg_signal[j] - ppg_signal[i]) * (k - i) / (j - i):\n",
    "                    visible = False\n",
    "                    break\n",
    "            if visible:\n",
    "                G.add_edge(i, j)\n",
    "                \n",
    "    return G\n",
    "\n",
    "# Convert Graph to Adjacency Matrix Image (CuPy)\n",
    "def graph_to_adjacency_matrix_image(G, size):\n",
    "    adj_matrix = cp.asarray(nx.to_numpy_array(G))\n",
    "    adj_matrix_resized = zoom(adj_matrix, (size / adj_matrix.shape[0], size / adj_matrix.shape[1]), order=0)\n",
    "    return adj_matrix_resized\n",
    "\n",
    "def graph_to_adjacency_matrix_GCN(G):\n",
    "    return nx.adjacency_matrix(G).todense()\n",
    "\n",
    "# Generate VG Image (CuPy)\n",
    "def generate_vg_image(ppg_signal, size):\n",
    "    G = create_visibility_graph(ppg_signal)\n",
    "    vg_image = graph_to_adjacency_matrix_image(G, size)\n",
    "    return cp.asnumpy(vg_image)\n",
    "\n",
    "# Process Signal and Generate VG Image\n",
    "def process_signal(i, ppg_signal, vg_image_size):\n",
    "    print(f\"Generating VG image for PPG signal {i + 1}\")\n",
    "    ppg_signal = ppg_signal.flatten()\n",
    "    vg_image = generate_vg_image(ppg_signal, vg_image_size)\n",
    "    return vg_image.flatten()\n",
    "\n",
    "# Combine and Process Data from Folder\n",
    "def combine_data_from_folder(folder_path, batch_size=500):\n",
    "    combined_ppg = []\n",
    "    combined_ecg = []\n",
    "    combined_seg_dbp = []\n",
    "    combined_seg_sbp = []\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        if not file_path.endswith('.npz'):\n",
    "            continue\n",
    "        \n",
    "        data = load_and_validate_data(file_path)\n",
    "        \n",
    "        if data is None:\n",
    "            print(f\"Skipping invalid file: {file_path}\")\n",
    "            continue\n",
    "        \n",
    "        ppg_f, ecg_f, seg_dbp, seg_sbp = data\n",
    "        \n",
    "        if ppg_f.ndim == 3:\n",
    "            for i in range(ppg_f.shape[0]):\n",
    "                preprocessed_ppg = preprocess_signal(ppg_f[i], 1000)\n",
    "                combined_ppg.append(preprocessed_ppg)\n",
    "        else:\n",
    "            print(f\"Skipping PPG data with unexpected shape: {ppg_f.shape}\")\n",
    "        \n",
    "        if ecg_f.ndim == 3:\n",
    "            for i in range(ecg_f.shape[0]):\n",
    "                preprocessed_ecg = preprocess_signal(ecg_f[i], 1000)\n",
    "                combined_ecg.append(preprocessed_ecg)\n",
    "        else:\n",
    "            print(f\"Skipping ECG data with unexpected shape: {ecg_f.shape}\")\n",
    "        \n",
    "        if seg_dbp.ndim == 2:\n",
    "            combined_seg_dbp.append(seg_dbp)\n",
    "        else:\n",
    "            print(f\"Skipping SegDBP data with unexpected shape: {seg_dbp.shape}\")\n",
    "        \n",
    "        if seg_sbp.ndim == 2:\n",
    "            combined_seg_sbp.append(seg_sbp)\n",
    "        else:\n",
    "            print(f\"Skipping SegSBP data with unexpected shape: {seg_sbp.shape}\")\n",
    "        \n",
    "        if len(combined_ppg) >= batch_size:\n",
    "            combined_ppg = np.stack(combined_ppg, axis=0)\n",
    "            combined_ecg = np.stack(combined_ecg, axis=0)\n",
    "            combined_seg_dbp = np.concatenate(combined_seg_dbp, axis=0)\n",
    "            combined_seg_sbp = np.concatenate(combined_seg_sbp, axis=0)\n",
    "            \n",
    "            yield combined_ppg, combined_ecg, combined_seg_dbp, combined_seg_sbp\n",
    "            \n",
    "            combined_ppg = []\n",
    "            combined_ecg = []\n",
    "            combined_seg_dbp = []\n",
    "            combined_seg_sbp = []\n",
    "\n",
    "    if combined_ppg:\n",
    "        combined_ppg = np.stack(combined_ppg, axis=0)\n",
    "    else:\n",
    "        combined_ppg = np.array([])\n",
    "        \n",
    "    if combined_ecg:\n",
    "        combined_ecg = np.stack(combined_ecg, axis=0)\n",
    "    else:\n",
    "        combined_ecg = np.array([])\n",
    "        \n",
    "    if combined_seg_dbp:\n",
    "        combined_seg_dbp = np.concatenate(combined_seg_dbp, axis=0)\n",
    "    else:\n",
    "        combined_seg_dbp = np.array([])\n",
    "        \n",
    "    if combined_seg_sbp:\n",
    "        combined_seg_sbp = np.concatenate(combined_seg_sbp, axis=0)\n",
    "    else:\n",
    "        combined_seg_sbp = np.array([])\n",
    "\n",
    "    yield combined_ppg, combined_ecg, combined_seg_dbp, combined_seg_sbp\n",
    "\n",
    "# Invert VG Images\n",
    "def invert_images(vg_images):\n",
    "    inverted_images = [255 - image for image in vg_images]\n",
    "    return inverted_images\n",
    "\n",
    "# Directory and Image Size\n",
    "folder_path = r'C:\\Users\\nihal\\Desktop\\NIHAL_IMP_DOCS\\Internship_PPG\\Validation_data'\n",
    "vg_image_size = 224  # VG image size\n",
    "\n",
    "# Create Output Directory\n",
    "output_dir = 'vg_images_validation'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Data Generator for Validation Data\n",
    "val_data_generator = combine_data_from_folder(folder_path, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82cbbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and Save VG Images\n",
    "for batch_idx, (combined_ppg_batch, combined_ecg_batch, combined_seg_dbp_batch, combined_seg_sbp_batch) in enumerate(val_data_generator):\n",
    "    \n",
    "    output_file = os.path.join(output_dir, f'val_vg_images_batch_{batch_idx + 1}.npz')\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"Batch {batch_idx + 1} already processed. Skipping...\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"Processing Batch {batch_idx + 1}...\")\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        vg_images = list(executor.map(process_signal, range(len(combined_ppg_batch)), combined_ppg_batch, [vg_image_size]*len(combined_ppg_batch)))\n",
    "        \n",
    "    np.savez_compressed(output_file, vg_images=vg_images)\n",
    "    print(f\"Batch {batch_idx + 1} processing complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
