{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfbd3fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import networkx as nx\n",
    "from scipy.ndimage import zoom\n",
    "def load_and_validate_data(file_path):\n",
    "    \"\"\"\n",
    "    Load data from a file and return it.\n",
    "    Return None if data is missing.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        loaded_data = np.load(file_path)\n",
    "        \n",
    "        ppg_f = loaded_data.get('ppg_f')\n",
    "        ecg_f = loaded_data.get('ecg_f')\n",
    "        seg_dbp = loaded_data.get('seg_dbp')\n",
    "        seg_sbp = loaded_data.get('seg_sbp')\n",
    "        \n",
    "        \n",
    "        if ppg_f is None or ecg_f is None or seg_dbp is None or seg_sbp is None:\n",
    "            return None\n",
    "\n",
    "        return ppg_f, ecg_f, seg_dbp, seg_sbp\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def combine_data_from_folder(folder_path, batch_size=100):\n",
    "    \"\"\"\n",
    "    Combine data from all valid files in the folder in batches.\n",
    "    \"\"\"\n",
    "    combined_ppg = []\n",
    "    combined_ecg = []\n",
    "    combined_seg_dbp = []\n",
    "    combined_seg_sbp = []\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        if not file_path.endswith('.npz'):\n",
    "            continue\n",
    "        \n",
    "        data = load_and_validate_data(file_path)\n",
    "        \n",
    "        if data is None:\n",
    "            print(f\"Skipping invalid file: {file_path}\")\n",
    "            continue\n",
    "        \n",
    "        ppg_f, ecg_f, seg_dbp, seg_sbp = data\n",
    "        \n",
    "        combined_ppg.append(ppg_f)\n",
    "        combined_ecg.append(ecg_f)\n",
    "        combined_seg_dbp.append(seg_dbp)\n",
    "        combined_seg_sbp.append(seg_sbp)\n",
    "        \n",
    "        if len(combined_ppg) >= batch_size:\n",
    "            combined_ppg = np.concatenate(combined_ppg, axis=0)\n",
    "            combined_ecg = np.concatenate(combined_ecg, axis=0)\n",
    "            combined_seg_dbp = np.concatenate(combined_seg_dbp, axis=0)\n",
    "            combined_seg_sbp = np.concatenate(combined_seg_sbp, axis=0)\n",
    "            \n",
    "            yield combined_ppg, combined_ecg, combined_seg_dbp, combined_seg_sbp\n",
    "            \n",
    "            combined_ppg = []\n",
    "            combined_ecg = []\n",
    "            combined_seg_dbp = []\n",
    "            combined_seg_sbp = []\n",
    "            \n",
    "\n",
    "    if combined_ppg:\n",
    "        combined_ppg = np.concatenate(combined_ppg, axis=0)\n",
    "    else:\n",
    "        combined_ppg = np.array([])\n",
    "        \n",
    "    if combined_ecg:\n",
    "        combined_ecg = np.concatenate(combined_ecg, axis=0)\n",
    "    else:\n",
    "        combined_ecg = np.array([])\n",
    "        \n",
    "    if combined_seg_dbp:\n",
    "        combined_seg_dbp = np.concatenate(combined_seg_dbp, axis=0)\n",
    "    else:\n",
    "        combined_seg_dbp = np.array([])\n",
    "        \n",
    "    if combined_seg_sbp:\n",
    "        combined_seg_sbp = np.concatenate(combined_seg_sbp, axis=0)\n",
    "    else:\n",
    "        combined_seg_sbp = np.array([])\n",
    "\n",
    "    yield combined_ppg, combined_ecg, combined_seg_dbp, combined_seg_sbp\n",
    "train_dir = 'C:\\\\Users\\\\nihal\\\\Desktop\\\\NIHAL_IMP_DOCS\\\\Internship_PPG\\\\Train_data'\n",
    "val_dir = 'C:\\\\Users\\\\nihal\\\\Desktop\\\\NIHAL_IMP_DOCS\\\\Internship_PPG\\\\Validation_data'\n",
    "test_dir = 'C:\\\\Users\\\\nihal\\\\Desktop\\\\NIHAL_IMP_DOCS\\\\Internship_PPG\\\\Test_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8820722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_visibility_graph(ppg_signal):\n",
    "    n = len(ppg_signal)\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(range(n))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            visible = True\n",
    "            for k in range(i + 1, j):\n",
    "                if ppg_signal[k] >= ppg_signal[i] + (ppg_signal[j] - ppg_signal[i]) * (k - i) / (j - i):\n",
    "                    visible = False\n",
    "                    break\n",
    "            if visible:\n",
    "                G.add_edge(i, j)\n",
    "                \n",
    "    return G\n",
    "\n",
    "def graph_to_adjacency_matrix_image(G, size):\n",
    "    adj_matrix = nx.to_numpy_array(G)\n",
    "    adj_matrix_resized = zoom(adj_matrix, (size / adj_matrix.shape[0], size / adj_matrix.shape[1]), order=0)\n",
    "    return adj_matrix_resized\n",
    "\n",
    "def graph_to_flattened_adjacency_matrix(G, size):\n",
    "    adj_matrix = nx.to_numpy_array(G)\n",
    "    adj_matrix_resized = zoom(adj_matrix, (size / adj_matrix.shape[0], size / adj_matrix.shape[1]), order=0)\n",
    "    flattened_adj = adj_matrix_resized.flatten()\n",
    "    return flattened_adj[:size * size]  \n",
    "\n",
    "def generate_vg_image(ppg_signal, size):\n",
    "    G = create_visibility_graph(ppg_signal)\n",
    "    vg_image = graph_to_adjacency_matrix_image(G, size)\n",
    "    return vg_image\n",
    "\n",
    "def process_signal(i, ppg_signal, vg_image_size):\n",
    "    \"\"\"\n",
    "    Generate a VG image for a given PPG signal.\n",
    "    \"\"\"\n",
    "    #print(f\"VG img {i + 1}\")\n",
    "    ppg_signal = ppg_signal.flatten()\n",
    "    vg_image = generate_vg_image(ppg_signal, vg_image_size)\n",
    "    return vg_image.flatten()\n",
    "\n",
    "vg_image_size=224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5061ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "def select_n_peak_window(ppg_signal, n_peaks=3):\n",
    "    ppg_3peak=[]\n",
    "    for ppg in ppg_signal:\n",
    "        x=ppg.flatten()\n",
    "        peaks, _ = find_peaks(x, distance=50)  \n",
    "    \n",
    "    \n",
    "    \n",
    "        if len(peaks) < n_peaks:\n",
    "            raise ValueError(f\"Not enough peaks detected. Detected peaks: {len(peaks)}\")\n",
    "    \n",
    "    \n",
    "        start_index = peaks[0]\n",
    "        end_index = peaks[n_peaks - 1]  \n",
    "    \n",
    "    \n",
    "        ppg_window = x[start_index:end_index + 1]\n",
    "        ppg_3peak.append(np.array(ppg_window))\n",
    "    \n",
    "    return ppg_3peak\n",
    "\n",
    "def reshape_ppg_3_peaks(ppg_signal):\n",
    "    ppg_3_peak_reshaped = []\n",
    "\n",
    "    for ppg_window in ppg_signal:\n",
    "        reshaped_window = ppg_window.reshape(1, -1)  \n",
    "        ppg_3_peak_reshaped.append(np.array(reshaped_window))\n",
    "        \n",
    "    return ppg_3_peak_reshaped\n",
    "\n",
    "def reshape_ppg_3_peaks_224(ppg_signal):\n",
    "    ppg_3_peak_reshaped = []\n",
    "\n",
    "    for ppg_window in ppg_signal:\n",
    "        window = ppg_window[0:224]\n",
    "        reshaped_window = ppg_window.reshape(1, -1)  \n",
    "        ppg_3_peak_reshaped.append(np.array(reshaped_window))\n",
    "        \n",
    "    return ppg_3_peak_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9611350",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_generator = combine_data_from_folder(val_dir, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c7953d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "\n",
    "vg_image_dir = 'vg_images_validation'\n",
    "\n",
    "\n",
    "def load_vg_images(batch_idx):\n",
    "    vg_images_path = os.path.join(vg_image_dir, f'val_vg_images_batch_{batch_idx}.npz')\n",
    "    \n",
    "    if not os.path.exists(vg_images_path) :\n",
    "        print(f\"VG image files do not exist for Batch {batch_idx}.\")\n",
    "        return None\n",
    "    \n",
    "    vg_images = np.load(vg_images_path)['vg_images']\n",
    "\n",
    "    \n",
    "    return vg_images\n",
    "\n",
    "def plot_vg_images(vg_images, num_images=5, image_size=(224, 224)):\n",
    "    for i in range(min(num_images, vg_images.shape[0])):\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        # Reshape each VG image to its original 2D shape\n",
    "        img = vg_images[i].reshape(image_size)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'VG Image {i+1}')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244c05f0",
   "metadata": {},
   "source": [
    "# With Val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01ab007f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Batch 1...\n",
      "Batch 1 processing complete.\n",
      "Processing Batch 2...\n",
      "Batch 2 processing complete.\n",
      "Processing Batch 3...\n",
      "Batch 3 processing complete.\n",
      "Processing Batch 4...\n",
      "Batch 4 processing complete.\n",
      "Processing Batch 5...\n",
      "VG image files do not exist for Batch 5.\n",
      "No VG images found for Batch 5. Stopping...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_vg_images = []\n",
    "all_sbp_values = []\n",
    "all_dbp_values = []\n",
    "#all_ppg_node_values = []\n",
    "\n",
    "for batch_idx, (combined_ppg_batch, combined_ecg_batch, combined_seg_dbp_batch, combined_seg_sbp_batch) in enumerate(val_data_generator):\n",
    "    print(f\"Processing Batch {batch_idx + 1}...\")\n",
    "    \n",
    "    #if batch_idx + 1>2:\n",
    "       # break\n",
    "    vg_images = load_vg_images(batch_idx + 1)\n",
    "    if vg_images is None:\n",
    "        print(f\"No VG images found for Batch {batch_idx + 1}. Stopping...\")\n",
    "        break\n",
    "    \n",
    "    flattened_vg_images = np.array(vg_images)\n",
    "    #ppg_peaks_3=select_n_peak_window(combined_ppg_batch)\n",
    "    #ppg_peaks_3_reshaped=reshape_ppg_3_peaks(ppg_peaks_3)\n",
    "    #ppg_peaks_3_reshaped_224=reshape_ppg_3_peaks(combined_ppg_batch)\n",
    "    #all_ppg_node_values.append(np.array(ppg_peaks_3_reshaped_224))\n",
    "    all_vg_images.append(flattened_vg_images)\n",
    "    all_sbp_values.append(np.array(combined_seg_sbp_batch.flatten()))\n",
    "    all_dbp_values.append(np.array(combined_seg_dbp_batch.flatten()))\n",
    "\n",
    "    print(f\"Batch {batch_idx + 1} processing complete.\")\n",
    "    \n",
    "#all_ppg_node_values = np.concatenate(all_ppg_node_values, axis=0)\n",
    "all_vg_images = np.concatenate(all_vg_images, axis=0)\n",
    "all_sbp_values = np.concatenate(all_sbp_values, axis=0)\n",
    "all_dbp_values = np.concatenate(all_dbp_values, axis=0)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b65b6805",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.column_stack((all_sbp_values, all_dbp_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fedf9683-eecd-4126-bda8-1eeefb9f08ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4149\n",
      "4149\n"
     ]
    }
   ],
   "source": [
    "print(len(all_vg_images))\n",
    "print(len(all_sbp_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ceb221b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "vg_images_normal = np.array(all_vg_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d15c36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Function to generate image batches\n",
    "def image_generator(images, labels, batch_size):\n",
    "    num_samples = images.shape[0]\n",
    "    while True:\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_images = images[offset:offset+batch_size]\n",
    "            batch_labels = labels[offset:offset+batch_size]\n",
    "            batch_images_reshaped = batch_images.reshape(-1, 224, 224, 1)\n",
    "            batch_images_rgb = np.concatenate([batch_images_reshaped] * 3, axis=-1)\n",
    "            batch_images_preprocessed = preprocess_input(batch_images_rgb)\n",
    "            yield batch_images_preprocessed, batch_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a3025d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 512)               12845568  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32869952 (125.39 MB)\n",
      "Trainable params: 12845568 (49.00 MB)\n",
      "Non-trainable params: 20024384 (76.39 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten(name='flatten')(x)\n",
    "#x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "#x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "output = Dense(512, activation='linear',name='fc1')(x)  \n",
    "\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1041038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = vg_images_normal\n",
    "labels = y\n",
    "num_samples = images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b783cd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    }
   ],
   "source": [
    "# Define a new model to extract features from the 'fc1' layer of the trained model\n",
    "feature_extractor = Model(inputs=model.input, outputs=model.get_layer('fc1').output)\n",
    "\n",
    "# Function to extract features\n",
    "def extract_features(generator, num_samples):\n",
    "    features = []\n",
    "    for batch_images, _ in generator:\n",
    "        batch_features = feature_extractor.predict(batch_images)\n",
    "        features.append(batch_features)\n",
    "        if len(features) * batch_size >= num_samples:\n",
    "            break\n",
    "    return np.vstack(features)\n",
    "\n",
    "\n",
    "feature_generator_normal = image_generator(images, np.zeros((num_samples,)), batch_size)\n",
    "\n",
    "\n",
    "features_normal = extract_features(feature_generator_normal, num_samples)\n",
    "\n",
    "\n",
    "features_normal_flattened= features_normal.reshape(features_normal.shape[0],-1)\n",
    "\n",
    "\n",
    "features= features_normal_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8f38116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "vg_features_train,vg_features_test,label_vgg_train,label_vgg_test=train_test_split(features,labels, test_size=0.2, random_state=42)\n",
    "ridge_model = Ridge(alpha=1.0)  \n",
    "ridge_model.fit(vg_features_train, label_vgg_train)\n",
    "\n",
    "\n",
    "predicted_values_split = ridge_model.predict(vg_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a822d79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBP Metrics: R=0.5744753672137302, MAE=11.443205502763947, RMSE=15.437279804635498, ME±SD=(0.30231606200353617, 15.434319316551074)\n",
      "DBP Metrics: R=0.6478334648846578, MAE=6.440628848545877, RMSE=8.834369097467382, ME±SD=(0.060790584063006914, 8.834159940547599)\n"
     ]
    }
   ],
   "source": [
    "predicted_sbp =predicted_values_split[:, 0]  # Assuming the first column is SBP\n",
    "predicted_dbp =predicted_values_split[:, 1]  # Assuming the second column is DBP\n",
    "\n",
    "true_sbp = label_vgg_test[:, 0]  # True SBP values from q\n",
    "true_dbp = label_vgg_test[:, 1]  # True DBP values from q\n",
    "\n",
    "def calculate_metrics(predicted, true):\n",
    "    # Calculate R (correlation coefficient)\n",
    "    R = np.corrcoef(predicted, true)[0, 1]\n",
    "\n",
    "    # Calculate MAE (Mean Absolute Error)\n",
    "    MAE = np.mean(np.abs(predicted - true))\n",
    "\n",
    "    # Calculate RMSE (Root Mean Squared Error)\n",
    "    RMSE = np.sqrt(np.mean((predicted - true) ** 2))\n",
    "\n",
    "    # Calculate ME ± SD (Mean Error ± Standard Deviation)\n",
    "    ME = np.mean(predicted - true)\n",
    "    SD = np.std(predicted - true)\n",
    "\n",
    "    return R, MAE, RMSE, (ME, SD)\n",
    "\n",
    "# Calculate metrics for SBP\n",
    "sbp_metrics = calculate_metrics(predicted_sbp, true_sbp)\n",
    "print(f\"SBP Metrics: R={sbp_metrics[0]}, MAE={sbp_metrics[1]}, RMSE={sbp_metrics[2]}, ME±SD={sbp_metrics[3]}\")\n",
    "\n",
    "# Calculate metrics for DBP\n",
    "dbp_metrics = calculate_metrics(predicted_dbp, true_dbp)\n",
    "print(f\"DBP Metrics: R={dbp_metrics[0]}, MAE={dbp_metrics[1]}, RMSE={dbp_metrics[2]}, ME±SD={dbp_metrics[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73a38b7a-bc37-4db6-bea9-515f5b8971b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10702"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecd98355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 1., 1., 0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vg_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f18418b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (combined_ppg_batch, combined_ecg_batch, combined_seg_dbp_batch, combined_seg_sbp_batch) in enumerate(train_data_generator):\n",
    "    peak=select_n_peak_window(combined_ppg_batch)\n",
    "    peak_reshaped=reshape_ppg_3_peaks(peak)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "788ab0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.62155461e-01, 3.61261763e-01, 3.57333689e-01, 3.50510351e-01,\n",
       "        3.41094774e-01, 3.29426638e-01, 3.15972071e-01, 3.01228797e-01,\n",
       "        2.85693173e-01, 2.69866566e-01, 2.54180109e-01, 2.39038403e-01,\n",
       "        2.24749350e-01, 2.11488633e-01, 1.99420712e-01, 1.88569369e-01,\n",
       "        1.78900548e-01, 1.70347126e-01, 1.62707639e-01, 1.55884837e-01,\n",
       "        1.49698104e-01, 1.43946993e-01, 1.38564384e-01, 1.33369253e-01,\n",
       "        1.28320207e-01, 1.23440963e-01, 1.18663800e-01, 1.14022183e-01,\n",
       "        1.09640159e-01, 1.05578577e-01, 1.01859327e-01, 9.86060221e-02,\n",
       "        9.59081935e-02, 9.37782857e-02, 9.22286129e-02, 9.12446371e-02,\n",
       "        9.08007807e-02, 9.08296620e-02, 9.11501782e-02, 9.16466019e-02,\n",
       "        9.22481286e-02, 9.27061253e-02, 9.28995333e-02, 9.27902529e-02,\n",
       "        9.22410298e-02, 9.12210127e-02, 8.97845497e-02, 8.80049087e-02,\n",
       "        8.59567242e-02, 8.37907948e-02, 8.16973394e-02, 7.98209804e-02,\n",
       "        7.83189467e-02, 7.73265749e-02, 7.69107144e-02, 7.70949605e-02,\n",
       "        7.78275281e-02, 7.89415304e-02, 8.02608730e-02, 8.15147364e-02,\n",
       "        8.23417236e-02, 8.24953722e-02, 8.16805583e-02, 7.96305427e-02,\n",
       "        7.63649195e-02, 7.19060902e-02, 6.64860742e-02, 6.06943299e-02,\n",
       "        5.50918248e-02, 5.06432719e-02, 4.84094143e-02, 4.94677635e-02,\n",
       "        5.51607237e-02, 6.65466416e-02, 8.47498513e-02, 1.10686315e-01,\n",
       "        1.44837948e-01, 1.87416224e-01, 2.38202103e-01, 2.96618367e-01,\n",
       "        3.61427672e-01, 4.31054114e-01, 5.03675204e-01, 5.76996705e-01,\n",
       "        6.48629297e-01, 7.16202395e-01, 7.77376419e-01, 8.29898844e-01,\n",
       "        8.72042616e-01, 9.02643292e-01, 9.20754769e-01, 9.26083430e-01,\n",
       "        9.19057947e-01, 9.00573436e-01, 8.72021567e-01, 8.35064268e-01,\n",
       "        7.91742570e-01, 7.44342030e-01, 6.94943044e-01, 6.45631912e-01,\n",
       "        5.98340134e-01, 5.54516272e-01, 5.15279531e-01, 4.81393059e-01,\n",
       "        4.53190045e-01, 4.30547107e-01, 4.12964799e-01, 3.99843485e-01,\n",
       "        3.90304994e-01, 3.83329007e-01, 3.78041367e-01, 3.73522163e-01,\n",
       "        3.69101793e-01, 3.64264586e-01, 3.58695735e-01, 3.52388104e-01,\n",
       "        3.45363654e-01, 3.38021079e-01, 3.30746225e-01, 3.23911837e-01,\n",
       "        3.18098322e-01, 3.13678288e-01, 3.10981124e-01, 3.10143679e-01,\n",
       "        3.11254270e-01, 3.14213622e-01, 3.18623105e-01, 3.24182261e-01,\n",
       "        3.30342248e-01, 3.36516119e-01, 3.42193042e-01, 3.46760868e-01,\n",
       "        3.49759373e-01, 3.50811094e-01, 3.49651764e-01, 3.46112162e-01,\n",
       "        3.40192689e-01, 3.32037858e-01, 3.21819589e-01, 3.09894040e-01,\n",
       "        2.96616034e-01, 2.82380365e-01, 2.67613588e-01, 2.52663881e-01,\n",
       "        2.37930229e-01, 2.23685148e-01, 2.10142626e-01, 1.97491455e-01,\n",
       "        1.85808348e-01, 1.75178662e-01, 1.65520962e-01, 1.56815773e-01,\n",
       "        1.48989947e-01, 1.41865965e-01, 1.35459435e-01, 1.29563894e-01,\n",
       "        1.24095533e-01, 1.19098512e-01, 1.14380954e-01, 1.09962673e-01,\n",
       "        1.05867015e-01, 1.02011833e-01, 9.84653493e-02, 9.52210106e-02,\n",
       "        9.22497223e-02, 8.96461325e-02, 8.73806263e-02, 8.54086881e-02,\n",
       "        8.37888335e-02, 8.24375960e-02, 8.13180348e-02, 8.04111649e-02,\n",
       "        7.95582145e-02, 7.87383356e-02, 7.78958877e-02, 7.68707796e-02,\n",
       "        7.56144138e-02, 7.40802279e-02, 7.22278120e-02, 7.00085355e-02,\n",
       "        6.74358524e-02, 6.46081728e-02, 6.15298306e-02, 5.83643047e-02,\n",
       "        5.52569152e-02, 5.23123893e-02, 4.97215558e-02, 4.75524155e-02,\n",
       "        4.59918807e-02, 4.49940570e-02, 4.44984237e-02, 4.45044376e-02,\n",
       "        4.46948175e-02, 4.49075822e-02, 4.48511476e-02, 4.41252871e-02,\n",
       "        4.25433592e-02, 3.98332036e-02, 3.58593878e-02, 3.06913956e-02,\n",
       "        2.44750299e-02, 1.76384016e-02, 1.08338105e-02, 4.89893447e-03,\n",
       "        8.94761119e-04, 0.00000000e+00, 3.47904346e-03, 1.26289345e-02,\n",
       "        2.87269049e-02, 5.27127188e-02, 8.52504127e-02, 1.26826666e-01,\n",
       "        1.77392285e-01, 2.36405961e-01, 3.02762423e-01, 3.75036296e-01,\n",
       "        4.51445415e-01, 5.29597535e-01, 6.07051868e-01, 6.81331905e-01,\n",
       "        7.49807585e-01, 8.10090531e-01, 8.60283496e-01, 8.98806083e-01,\n",
       "        9.24434212e-01, 9.36757755e-01]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_reshaped[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90d80f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., ..., 1., 1., 0.],\n",
       "       [0., 1., 0., ..., 0., 1., 0.],\n",
       "       [0., 1., 1., ..., 1., 1., 0.],\n",
       "       ...,\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 1., 1., 0.],\n",
       "       [0., 1., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vg_images_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "252bb868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., ..., 1., 1., 0.],\n",
       "       [0., 1., 0., ..., 0., 1., 0.],\n",
       "       [0., 1., 1., ..., 1., 1., 0.],\n",
       "       ...,\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 1., 1., 0.],\n",
       "       [0., 1., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vg_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59db59ba-eb6c-42f7-891c-72ea47410648",
   "metadata": {},
   "source": [
    "# MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3037d5b0-27f2-4825-8615-aafddc8581d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vg_images_normal = np.array(all_vg_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb83e531-dcbd-492b-8f9a-d7cf08487fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Function to generate image batches\n",
    "def image_generator(images, labels, batch_size):\n",
    "    num_samples = images.shape[0]\n",
    "    while True:\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_images = images[offset:offset+batch_size]\n",
    "            batch_labels = labels[offset:offset+batch_size]\n",
    "            batch_images_reshaped = batch_images.reshape(-1, 224, 224, 1)\n",
    "            batch_images_rgb = np.concatenate([batch_images_reshaped] * 3, axis=-1)\n",
    "            batch_images_preprocessed = preprocess_input(batch_images_rgb)\n",
    "            yield batch_images_preprocessed, batch_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "025219d2-0a0b-4306-bb15-248f7356f9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 112, 112, 32)      864       \n",
      "                                                                 \n",
      " conv1_bn (BatchNormalizati  (None, 112, 112, 32)      128       \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv1_relu (ReLU)           (None, 112, 112, 32)      0         \n",
      "                                                                 \n",
      " conv_dw_1 (DepthwiseConv2D  (None, 112, 112, 32)      288       \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_1_bn (BatchNormali  (None, 112, 112, 32)      128       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_1_relu (ReLU)       (None, 112, 112, 32)      0         \n",
      "                                                                 \n",
      " conv_pw_1 (Conv2D)          (None, 112, 112, 64)      2048      \n",
      "                                                                 \n",
      " conv_pw_1_bn (BatchNormali  (None, 112, 112, 64)      256       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_1_relu (ReLU)       (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " conv_pad_2 (ZeroPadding2D)  (None, 113, 113, 64)      0         \n",
      "                                                                 \n",
      " conv_dw_2 (DepthwiseConv2D  (None, 56, 56, 64)        576       \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_2_bn (BatchNormali  (None, 56, 56, 64)        256       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_2_relu (ReLU)       (None, 56, 56, 64)        0         \n",
      "                                                                 \n",
      " conv_pw_2 (Conv2D)          (None, 56, 56, 128)       8192      \n",
      "                                                                 \n",
      " conv_pw_2_bn (BatchNormali  (None, 56, 56, 128)       512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_2_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_3 (DepthwiseConv2D  (None, 56, 56, 128)       1152      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_3_bn (BatchNormali  (None, 56, 56, 128)       512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_3_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_3 (Conv2D)          (None, 56, 56, 128)       16384     \n",
      "                                                                 \n",
      " conv_pw_3_bn (BatchNormali  (None, 56, 56, 128)       512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_3_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_pad_4 (ZeroPadding2D)  (None, 57, 57, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_4 (DepthwiseConv2D  (None, 28, 28, 128)       1152      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_4_bn (BatchNormali  (None, 28, 28, 128)       512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_4_relu (ReLU)       (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_4 (Conv2D)          (None, 28, 28, 256)       32768     \n",
      "                                                                 \n",
      " conv_pw_4_bn (BatchNormali  (None, 28, 28, 256)       1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_4_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_dw_5 (DepthwiseConv2D  (None, 28, 28, 256)       2304      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_5_bn (BatchNormali  (None, 28, 28, 256)       1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_5_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_pw_5 (Conv2D)          (None, 28, 28, 256)       65536     \n",
      "                                                                 \n",
      " conv_pw_5_bn (BatchNormali  (None, 28, 28, 256)       1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_5_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_pad_6 (ZeroPadding2D)  (None, 29, 29, 256)       0         \n",
      "                                                                 \n",
      " conv_dw_6 (DepthwiseConv2D  (None, 14, 14, 256)       2304      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_6_bn (BatchNormali  (None, 14, 14, 256)       1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_6_relu (ReLU)       (None, 14, 14, 256)       0         \n",
      "                                                                 \n",
      " conv_pw_6 (Conv2D)          (None, 14, 14, 512)       131072    \n",
      "                                                                 \n",
      " conv_pw_6_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_6_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_7 (DepthwiseConv2D  (None, 14, 14, 512)       4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_7_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_7_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_7 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_7_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_7_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_8 (DepthwiseConv2D  (None, 14, 14, 512)       4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_8_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_8_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_8 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_8_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_8_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_9 (DepthwiseConv2D  (None, 14, 14, 512)       4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_9_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_9_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_9 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_9_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_9_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_10 (DepthwiseConv2  (None, 14, 14, 512)       4608      \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv_dw_10_bn (BatchNormal  (None, 14, 14, 512)       2048      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_dw_10_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_10 (Conv2D)         (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_10_bn (BatchNormal  (None, 14, 14, 512)       2048      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_pw_10_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_11 (DepthwiseConv2  (None, 14, 14, 512)       4608      \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv_dw_11_bn (BatchNormal  (None, 14, 14, 512)       2048      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_dw_11_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_11 (Conv2D)         (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_11_bn (BatchNormal  (None, 14, 14, 512)       2048      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_pw_11_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pad_12 (ZeroPadding2D  (None, 15, 15, 512)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_12 (DepthwiseConv2  (None, 7, 7, 512)         4608      \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv_dw_12_bn (BatchNormal  (None, 7, 7, 512)         2048      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_dw_12_relu (ReLU)      (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_12 (Conv2D)         (None, 7, 7, 1024)        524288    \n",
      "                                                                 \n",
      " conv_pw_12_bn (BatchNormal  (None, 7, 7, 1024)        4096      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_pw_12_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " conv_dw_13 (DepthwiseConv2  (None, 7, 7, 1024)        9216      \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv_dw_13_bn (BatchNormal  (None, 7, 7, 1024)        4096      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_dw_13_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " conv_pw_13 (Conv2D)         (None, 7, 7, 1024)        1048576   \n",
      "                                                                 \n",
      " conv_pw_13_bn (BatchNormal  (None, 7, 7, 1024)        4096      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_pw_13_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 50176)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 512)               25690624  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28919488 (110.32 MB)\n",
      "Trainable params: 25690624 (98.00 MB)\n",
      "Non-trainable params: 3228864 (12.32 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "\n",
    "base_model_mobile = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "\n",
    "for layer in base_model_mobile.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "x = base_model_mobile.output\n",
    "x = Flatten(name='flatten')(x)\n",
    "output = Dense(512, activation='linear', name='fc1')(x)\n",
    "\n",
    "\n",
    "model_mobile = Model(inputs=base_model_mobile.input, outputs=output)\n",
    "\n",
    "model_mobile.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e5de447-37c8-4b48-891b-0029d5dae9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = vg_images_normal\n",
    "labels = y\n",
    "num_samples = images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f3afac3-74cc-47a7-bad8-a465021d8fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 560ms/step\n",
      "1/1 [==============================] - 1s 515ms/step\n",
      "1/1 [==============================] - 1s 535ms/step\n",
      "1/1 [==============================] - 1s 514ms/step\n",
      "1/1 [==============================] - 1s 537ms/step\n",
      "1/1 [==============================] - 1s 522ms/step\n",
      "1/1 [==============================] - 1s 561ms/step\n",
      "1/1 [==============================] - 1s 541ms/step\n",
      "1/1 [==============================] - 1s 537ms/step\n",
      "1/1 [==============================] - 1s 537ms/step\n",
      "1/1 [==============================] - 1s 553ms/step\n",
      "1/1 [==============================] - 1s 583ms/step\n",
      "1/1 [==============================] - 1s 551ms/step\n",
      "1/1 [==============================] - 1s 600ms/step\n",
      "1/1 [==============================] - 1s 560ms/step\n",
      "1/1 [==============================] - 1s 578ms/step\n",
      "1/1 [==============================] - 1s 573ms/step\n",
      "1/1 [==============================] - 1s 580ms/step\n",
      "1/1 [==============================] - 1s 630ms/step\n",
      "1/1 [==============================] - 1s 651ms/step\n",
      "1/1 [==============================] - 1s 666ms/step\n",
      "1/1 [==============================] - 1s 539ms/step\n",
      "1/1 [==============================] - 1s 573ms/step\n",
      "1/1 [==============================] - 1s 519ms/step\n",
      "1/1 [==============================] - 0s 490ms/step\n",
      "1/1 [==============================] - 1s 500ms/step\n",
      "1/1 [==============================] - 1s 518ms/step\n",
      "1/1 [==============================] - 1s 516ms/step\n",
      "1/1 [==============================] - 1s 541ms/step\n",
      "1/1 [==============================] - 1s 501ms/step\n",
      "1/1 [==============================] - 1s 512ms/step\n",
      "1/1 [==============================] - 1s 505ms/step\n",
      "1/1 [==============================] - 1s 591ms/step\n",
      "1/1 [==============================] - 1s 525ms/step\n",
      "1/1 [==============================] - 1s 572ms/step\n",
      "1/1 [==============================] - 1s 560ms/step\n",
      "1/1 [==============================] - 1s 672ms/step\n",
      "1/1 [==============================] - 1s 593ms/step\n",
      "1/1 [==============================] - 1s 596ms/step\n",
      "1/1 [==============================] - 1s 556ms/step\n",
      "1/1 [==============================] - 1s 585ms/step\n",
      "1/1 [==============================] - 1s 637ms/step\n",
      "1/1 [==============================] - 1s 656ms/step\n",
      "1/1 [==============================] - 1s 553ms/step\n",
      "1/1 [==============================] - 1s 594ms/step\n",
      "1/1 [==============================] - 1s 620ms/step\n",
      "1/1 [==============================] - 1s 522ms/step\n",
      "1/1 [==============================] - 1s 501ms/step\n",
      "1/1 [==============================] - 1s 561ms/step\n",
      "1/1 [==============================] - 1s 565ms/step\n",
      "1/1 [==============================] - 1s 508ms/step\n",
      "1/1 [==============================] - 1s 514ms/step\n",
      "1/1 [==============================] - 1s 536ms/step\n",
      "1/1 [==============================] - 1s 588ms/step\n",
      "1/1 [==============================] - 1s 539ms/step\n",
      "1/1 [==============================] - 1s 522ms/step\n",
      "1/1 [==============================] - 1s 541ms/step\n",
      "1/1 [==============================] - 1s 547ms/step\n",
      "1/1 [==============================] - 1s 538ms/step\n",
      "1/1 [==============================] - 1s 590ms/step\n",
      "1/1 [==============================] - 1s 543ms/step\n",
      "1/1 [==============================] - 1s 604ms/step\n",
      "1/1 [==============================] - 1s 563ms/step\n",
      "1/1 [==============================] - 1s 571ms/step\n",
      "1/1 [==============================] - 1s 555ms/step\n",
      "1/1 [==============================] - 1s 592ms/step\n",
      "1/1 [==============================] - 1s 565ms/step\n",
      "1/1 [==============================] - 1s 534ms/step\n",
      "1/1 [==============================] - 1s 563ms/step\n",
      "1/1 [==============================] - 1s 515ms/step\n",
      "1/1 [==============================] - 1s 547ms/step\n",
      "1/1 [==============================] - 1s 526ms/step\n",
      "1/1 [==============================] - 1s 510ms/step\n",
      "1/1 [==============================] - 0s 494ms/step\n",
      "1/1 [==============================] - 1s 517ms/step\n",
      "1/1 [==============================] - 0s 493ms/step\n",
      "1/1 [==============================] - 0s 492ms/step\n",
      "1/1 [==============================] - 1s 506ms/step\n",
      "1/1 [==============================] - 0s 495ms/step\n",
      "1/1 [==============================] - 1s 515ms/step\n",
      "1/1 [==============================] - 0s 496ms/step\n",
      "1/1 [==============================] - 1s 520ms/step\n",
      "1/1 [==============================] - 1s 568ms/step\n",
      "1/1 [==============================] - 1s 572ms/step\n",
      "1/1 [==============================] - 1s 602ms/step\n",
      "1/1 [==============================] - 1s 584ms/step\n",
      "1/1 [==============================] - 1s 540ms/step\n",
      "1/1 [==============================] - 1s 585ms/step\n",
      "1/1 [==============================] - 1s 549ms/step\n",
      "1/1 [==============================] - 1s 573ms/step\n",
      "1/1 [==============================] - 1s 570ms/step\n",
      "1/1 [==============================] - 1s 544ms/step\n",
      "1/1 [==============================] - 1s 575ms/step\n",
      "1/1 [==============================] - 1s 566ms/step\n",
      "1/1 [==============================] - 1s 559ms/step\n",
      "1/1 [==============================] - 0s 491ms/step\n",
      "1/1 [==============================] - 1s 528ms/step\n",
      "1/1 [==============================] - 1s 514ms/step\n",
      "1/1 [==============================] - 1s 504ms/step\n",
      "1/1 [==============================] - 1s 538ms/step\n",
      "1/1 [==============================] - 1s 548ms/step\n",
      "1/1 [==============================] - 1s 549ms/step\n",
      "1/1 [==============================] - 1s 505ms/step\n",
      "1/1 [==============================] - 1s 502ms/step\n",
      "1/1 [==============================] - 1s 522ms/step\n",
      "1/1 [==============================] - 0s 487ms/step\n",
      "1/1 [==============================] - 1s 522ms/step\n",
      "1/1 [==============================] - 1s 542ms/step\n",
      "1/1 [==============================] - 1s 567ms/step\n",
      "1/1 [==============================] - 1s 561ms/step\n",
      "1/1 [==============================] - 1s 662ms/step\n",
      "1/1 [==============================] - 1s 564ms/step\n",
      "1/1 [==============================] - 1s 545ms/step\n",
      "1/1 [==============================] - 1s 550ms/step\n",
      "1/1 [==============================] - 1s 553ms/step\n",
      "1/1 [==============================] - 1s 567ms/step\n",
      "1/1 [==============================] - 1s 560ms/step\n",
      "1/1 [==============================] - 1s 662ms/step\n",
      "1/1 [==============================] - 1s 643ms/step\n",
      "1/1 [==============================] - 1s 575ms/step\n",
      "1/1 [==============================] - 1s 529ms/step\n",
      "1/1 [==============================] - 1s 516ms/step\n",
      "1/1 [==============================] - 0s 495ms/step\n",
      "1/1 [==============================] - 1s 518ms/step\n",
      "1/1 [==============================] - 1s 506ms/step\n",
      "1/1 [==============================] - 1s 508ms/step\n",
      "1/1 [==============================] - 1s 525ms/step\n",
      "1/1 [==============================] - 1s 507ms/step\n",
      "1/1 [==============================] - 1s 737ms/step\n"
     ]
    }
   ],
   "source": [
    "# Define a new model to extract features from the 'fc1' layer of the trained model\n",
    "feature_extractor_mobile = Model(inputs=model_mobile.input, outputs=model_mobile.get_layer('fc1').output)\n",
    "\n",
    "# Function to extract features\n",
    "def extract_features(generator, num_samples):\n",
    "    features = []\n",
    "    for batch_images, _ in generator:\n",
    "        batch_features = feature_extractor_mobile.predict(batch_images)\n",
    "        features.append(batch_features)\n",
    "        if len(features) * batch_size >= num_samples:\n",
    "            break\n",
    "    return np.vstack(features)\n",
    "\n",
    "\n",
    "feature_generator_normal_1 = image_generator(images, np.zeros((num_samples,)), batch_size)\n",
    "\n",
    "features_normal_1 = extract_features(feature_generator_normal_1, num_samples)\n",
    "\n",
    "features_normal_flattened_1= features_normal_1.reshape(features_normal_1.shape[0],-1)\n",
    "\n",
    "features_1= features_normal_flattened_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5a0049c-5809-4b71-b7e5-bdbc1f89628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Mobile_train,Mobile_test,label_train,label_test=train_test_split(features_1,labels, test_size=0.2, random_state=42)\n",
    "ridge_model = Ridge(alpha=1.0)  \n",
    "ridge_model.fit(Mobile_train, label_train)\n",
    "\n",
    "\n",
    "predicted_mobile = ridge_model.predict(Mobile_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b07d07c0-88e0-416e-9a17-7efb5a0b14a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBP Metrics: R=0.7496319155604708, MAE=9.518621532486849, RMSE=12.385240064082302, ME±SD=(-0.5771832976955933, 12.371783658220451)\n",
      "DBP Metrics: R=0.6958436174050171, MAE=3.8236322081578247, RMSE=5.347403835193292, ME±SD=(-0.07850590920669992, 5.346827526567465)\n"
     ]
    }
   ],
   "source": [
    "predicted_sbp =predicted_mobile[:, 0]  # Assuming the first column is SBP\n",
    "predicted_dbp =predicted_mobile[:, 1]  # Assuming the second column is DBP\n",
    "\n",
    "true_sbp = label_test[:, 0]  # True SBP values from q\n",
    "true_dbp = label_test[:, 1]  # True DBP values from q\n",
    "\n",
    "def calculate_metrics(predicted, true):\n",
    "    # Calculate R (correlation coefficient)\n",
    "    R = np.corrcoef(predicted, true)[0, 1]\n",
    "\n",
    "    # Calculate MAE (Mean Absolute Error)\n",
    "    MAE = np.mean(np.abs(predicted - true))\n",
    "\n",
    "    # Calculate RMSE (Root Mean Squared Error)\n",
    "    RMSE = np.sqrt(np.mean((predicted - true) ** 2))\n",
    "\n",
    "    # Calculate ME ± SD (Mean Error ± Standard Deviation)\n",
    "    ME = np.mean(predicted - true)\n",
    "    SD = np.std(predicted - true)\n",
    "\n",
    "    return R, MAE, RMSE, (ME, SD)\n",
    "\n",
    "# Calculate metrics for SBP\n",
    "sbp_metrics = calculate_metrics(predicted_sbp, true_sbp)\n",
    "print(f\"SBP Metrics: R={sbp_metrics[0]}, MAE={sbp_metrics[1]}, RMSE={sbp_metrics[2]}, ME±SD={sbp_metrics[3]}\")\n",
    "\n",
    "# Calculate metrics for DBP\n",
    "dbp_metrics = calculate_metrics(predicted_dbp, true_dbp)\n",
    "print(f\"DBP Metrics: R={dbp_metrics[0]}, MAE={dbp_metrics[1]}, RMSE={dbp_metrics[2]}, ME±SD={dbp_metrics[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d88846",
   "metadata": {},
   "source": [
    "# FULL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "847eef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications.vgg19 import VGG19,preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Define VGG19 model for feature extraction\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = base_model.output\n",
    "x = Flatten(name='flatten')(x)\n",
    "output = Dense(512, activation='linear', name='fc1')(x)\n",
    "feature_extractor = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Initialize Ridge Regression model\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# Initialize SGD Regressor model\n",
    "sbp_model = SGDRegressor()\n",
    "dbp_model = SGDRegressor()\n",
    "\n",
    "\n",
    "def process_and_train(batch_idx, vg_images, sbp_values, dbp_values):\n",
    "    # Reshape VG images for VGG19 input\n",
    "    print(f\"Batch {batch_idx + 1} processing for training.\")\n",
    "    vg_images_reshaped = vg_images.reshape(-1, 224, 224, 1)\n",
    "    vg_images_rgb = np.concatenate([vg_images_reshaped] * 3, axis=-1)\n",
    "    \n",
    "    # Preprocess images\n",
    "    vg_images_preprocessed = preprocess_input(vg_images_rgb)\n",
    "    \n",
    "    # Extract features using VGG19\n",
    "    #if tf.config.list_physical_devices('GPU'):\n",
    "        #with tf.device('/GPU:0'):\n",
    "            #features = feature_extractor.predict(vg_images_preprocessed, batch_size=32)\n",
    "    #else:\n",
    "        #features = feature_extractor.predict(vg_images_preprocessed, batch_size=32)\n",
    "        \n",
    "    features = feature_extractor.predict(vg_images_preprocessed)\n",
    "    \n",
    "    # Flatten features\n",
    "    features_flattened = features.reshape(features.shape[0], -1)\n",
    "    \n",
    "    # Combine SBP and DBP into a single array\n",
    "    #labels = np.column_stack((sbp_values, dbp_values))\n",
    "    \n",
    "    # Train Ridge Regression model\n",
    "    sbp_model.partial_fit(features_flattened, sbp_values)\n",
    "    dbp_model.partial_fit(features_flattened, dbp_values)\n",
    "    print(f\"Batch {batch_idx + 1} processed and used for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ab0bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 processing for training.\n",
      "159/159 [==============================] - 795s 5s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nihal\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nihal\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 processed and used for training.\n",
      "Batch 2 processing for training.\n",
      " 92/177 [==============>...............] - ETA: 7:45"
     ]
    }
   ],
   "source": [
    "# Iterate over batches\n",
    "for batch_idx, (combined_ppg_batch, combined_ecg_batch, combined_seg_dbp_batch, combined_seg_sbp_batch) in enumerate(train_data_generator):\n",
    "    # Load corresponding VG images\n",
    "    vg_images = load_vg_images(batch_idx + 1)\n",
    "    #print(np.array(vg_images))\n",
    "    vg_images=np.array(vg_images)\n",
    "    if vg_images is None:\n",
    "        print(f\"No VG images found for Batch {batch_idx + 1}. Stopping...\")\n",
    "        break\n",
    "    \n",
    "    # Process and train on the current batch\n",
    "    process_and_train(batch_idx, vg_images, combined_seg_sbp_batch, combined_seg_dbp_batch)\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45a1416",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_generator = combine_data_from_folder(test_dir, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce157a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "def process_and_predict(batch_idx, vg_images, sbp_values, dbp_values):\n",
    "    \"\"\"\n",
    "    Process VG images and predict SBP and DBP using Ridge Regression.\n",
    "    \"\"\"\n",
    "    print(f\"Batch {batch_idx + 1} processing for predicting.\")\n",
    "    \n",
    "    # Reshape VG images for VGG19 input\n",
    "    vg_images_reshaped = vg_images.reshape(-1, 224, 224, 1)\n",
    "    vg_images_rgb = np.concatenate([vg_images_reshaped] * 3, axis=-1)\n",
    "    \n",
    "    # Preprocess images\n",
    "    vg_images_preprocessed = preprocess_input(vg_images_rgb)\n",
    "    \n",
    "    # Extract features using VGG19\n",
    "    features = feature_extractor.predict(vg_images_preprocessed)\n",
    "    \n",
    "    # Flatten features\n",
    "    features_flattened = features.reshape(features.shape[0], -1)\n",
    "    \n",
    "    # Combine SBP and DBP into a single array\n",
    "    labels = np.column_stack((sbp_values, dbp_values))\n",
    "    \n",
    "    # Predict using Ridge Regression model\n",
    "    sbp_predictions = sbp_model.predict(features_flattened)\n",
    "    dbp_predictions = dbp_model.predict(features_flattened)\n",
    "    predictions = np.column_stack((sbp_predictions, dbp_predictions))\n",
    "    \n",
    "    # Calculate metrics for the current batch\n",
    "    mae = mean_absolute_error(labels, predictions)\n",
    "    rmse = np.sqrt(mean_squared_error(labels, predictions))\n",
    "    me = np.mean(predictions - labels, axis=0)\n",
    "    sd = np.std(predictions - labels, axis=0)\n",
    "    r2 = r2_score(labels, predictions)\n",
    "    \n",
    "    print(f\"Batch {batch_idx + 1} - MAE: {mae:.4f}, RMSE: {rmse:.4f}, ME: {me}, SD: {sd}, R2: {r2:.4f}\")\n",
    "    \n",
    "    return mae, rmse, me, sd, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe204fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metrics_in_batches(train_data_generator):\n",
    "    batch_mae = []\n",
    "    batch_rmse = []\n",
    "    batch_me = []\n",
    "    batch_sd = []\n",
    "    batch_r2 = []\n",
    "\n",
    "    for batch_idx, (combined_ppg_batch, combined_ecg_batch, combined_seg_dbp_batch, combined_seg_sbp_batch) in enumerate(train_data_generator):\n",
    "        # Load corresponding VG images\n",
    "        vg_images = load_vg_images(batch_idx + 1)\n",
    "        if vg_images is None:\n",
    "            print(f\"No VG images found for Batch {batch_idx + 1}. Stopping...\")\n",
    "            break\n",
    "        \n",
    "        # Process and predict on the current batch\n",
    "        mae, rmse, me, sd, r2 = process_and_predict(batch_idx, vg_images, combined_seg_sbp_batch, combined_seg_dbp_batch)\n",
    "        \n",
    "        # Append metrics to lists\n",
    "        batch_mae.append(mae)\n",
    "        batch_rmse.append(rmse)\n",
    "        batch_me.append(me)\n",
    "        batch_sd.append(sd)\n",
    "        batch_r2.append(r2)\n",
    "    \n",
    "    # Compute overall metrics\n",
    "    overall_mae = np.mean(batch_mae)\n",
    "    overall_rmse = np.mean(batch_rmse)\n",
    "    overall_me = np.mean(batch_me, axis=0)\n",
    "    overall_sd = np.mean(batch_sd, axis=0)\n",
    "    overall_r2 = np.mean(batch_r2)\n",
    "    \n",
    "    return overall_mae, overall_rmse, overall_me, overall_sd, overall_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b75438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "overall_mae, overall_rmse, overall_me, overall_sd, overall_r2 = evaluate_metrics_in_batches(train_data_generator)\n",
    "print(f\"Overall MAE: {overall_mae:.4f}\")\n",
    "print(f\"Overall RMSE: {overall_rmse:.4f}\")\n",
    "print(f\"Overall ME: {overall_me}\")\n",
    "print(f\"Overall SD: {overall_sd}\")\n",
    "print(f\"Overall R2: {overall_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaaafa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
